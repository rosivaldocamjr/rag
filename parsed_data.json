[
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nFrontispiece\nAbout the Standard\nThe Application Security Verification Standard is a list of application security requirements that ar‑\nchitects, developers, testers, security professionals, tool vendors, and consumers can use to define,\nbuild, test, and verify secure applications.\nCopyright and License\nVersion 5.0.0, May 2025\nFigure 1: license\nCopyright © 2008‑2025 The OWASP Foundation.\nThis document is released under the Creative Commons Attribution‑ShareAlike 4.0 International Li‑\ncense.\nFor any reuse or distribution, you must clearly communicate the license terms of this work to oth‑\ners.\nProject Leads\nElar Lang\nJosh C Grossman\nJim Manico\nDaniel Cuthbert\nWorking Group\nTobias Ahnoff\nRalph Andalis\nRyan Armstrong\nGabriel Corona\nMeghan Jacquot\nShanni Prutchi\nIman Sharafaldin\nEden Yardeni\nOther Major Contributors\nSjoerd Langkemper\nIsaac Lewis\n7",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 1
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nMark Carney\nSandro Gauci\nOther Contributors and Reviewers\nWe have included a list of the other contributors in Appendix E.\nIf a credit is missing from the 5.x credit list, please log a ticket at GitHub to be recognized in future\n5.x updates.\nThe Application Security Verification Standard builds on the work of those involved in ASVS 1.0 (2008)\nthrough 4.0 (2019). Much of the structure and many of the verification items that remain in ASVS to‑\nday were originally written by Andrew van der Stock, Mike Boberski, Jeff Williams, and Dave Wich‑\ners, among numerous other contributors. Thank you to everyone who has contributed in the past.\nFor a comprehensive list of earlier contributors, please consult each prior version.\nPreface\nWelcome to the Application Security Verification Standard (ASVS) Version 5.0.\nIntroduction\nOriginally launched in 2008 through a global community collaboration, the ASVS defines a compre‑\nhensive set of security requirements for designing, developing, and testing modern web applications\nand services.\nFollowing the release of ASVS 4.0 in 2019 and its minor update (v4.0.3) in 2021, Version 5.0 represents\na significant milestone—modernized to reflect the latest advances in software security.\nASVS 5.0 is the result of extensive contributions from project leaders, working group members, and\nthe wider OWASP community to update and improve this important standard.\nPrinciples behind version 5.0\nThis major revision has been developed with several key principles in mind:\n• Refined Scope and Focus: This version of the standard has been designed to align more di‑\nrectly with the foundational pillars in its name: Application, Security, Verification, and Stan‑\ndard. Requirements have been rewritten to emphasize the prevention of security flaws rather\nthan mandating specific technical implementations. Requirement texts are intended to be self‑\nexplanatory, explaining why they exist.\n8",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 2
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• Support for Documented Security Decisions: ASVS 5.0 introduces requirements for document‑\ning key security decisions. This enhances traceability and supports context‑sensitive imple‑\nmentations, allowing organizations to tailor their security posture to their specific needs and\nrisks.\n• Updated Levels: While ASVS retains its three‑tier model, the level definitions have evolved to\nmake the ASVS easier to adopt. Level 1 is designed as the initial step to adopting the ASVS, pro‑\nviding the first layer of defense. Level 2 represents a comprehensive view of standard security\npractices, and Level 3 addresses advanced, high‑assurance requirements.\n• Restructured and Expanded Content: ASVS 5.0 includes approximately 350 requirements across\n17 chapters. Chapters have been reorganized for clarity and usability. A two‑way mapping\nbetween v4.0 and v5.0 is provided to facilitate migration.\nLooking ahead\nJust as securing an application is never truly finished, neither is the ASVS. Although Version 5.0 is\na major release, development continues. This release allows the wider community to benefit from\nthe improvements and additions which have been accumulated but also lays the groundwork for\nfuture enhancements. This could include community‑driven efforts to create implementation and\nverification guidance built on top of the core requirement set.\nASVS 5.0 is designed to serve as a reliable foundation for secure software development. The commu‑\nnity is invited to adopt, contribute, and build upon this standard to collectively advance the state of\napplication security.\nWhat is the ASVS?\nThe Application Security Verification Standard (ASVS) defines security requirements for web appli‑\ncations and services, and it is a valuable resource for anyone aiming to design, develop, and maintain\nsecure applications or evaluate their security.\nThis chapter outlines the essential aspects of using the ASVS, including its scope, the structure of its\npriority‑based levels, and the primary use cases for the standard.\nScope of the ASVS\nThe scope of the ASVS is defined by its name: Application, Security, Verification, and Standard. It es‑\ntablishes which requirements are included or excluded, with the overarching goal of identifying the\nsecurity principles that must be achieved. The scope also considers documentation requirements,\nwhich serve as the foundation for implementation requirements.\n9",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 3
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nThere is no such thing as scope for attackers. Therefore, ASVS requirements should be evaluated\nalongside guidance for other aspects of the application lifecycle, including CI/CD processes, hosting,\nand operational activities.\nApplication\nASVS defines an “application”as the software product being developed, into which security controls\nmust be integrated. ASVS does not prescribe development lifecycle activities or dictate how the ap‑\nplication should be built via a CI/CD pipeline; instead, it specifies the security outcomes that must\nbe achieved within the product itself.\nComponents that serve, modify, or validate HTTP traffic, such as Web Application Firewalls (WAFs),\nload balancers, or proxies, may be considered part of the application for those specific purposes,\nas some security controls depend directly on them or can be implemented through them. These\ncomponents should be considered for requirements related to cached responses, rate limiting, or\nrestricting incoming and outgoing connections based on source and destination.\nConversely, ASVS generally excludes requirements that are not directly relevant to the application or\nwhere configuration is outside the application’s responsibility. For example, DNS issues are typically\nmanaged by a separate team or function.\nSimilarly, while the application is responsible for how it consumes input and produces output, if an\nexternal process interacts with the application or its data, it is considered out of scope for ASVS. For\ninstance, backing up the application or its data is usually the responsibility of an external process\nand is not controlled by the application or its developers.\nSecurity\nEvery requirement must have a demonstrable impact on security. The absence of a requirement\nmust result in a less secure application, and implementing the requirement must reduce either the\nlikelihood or the impact of a security risk.\nAll other considerations, such as functional aspects, code style, or policy requirements, are out of\nscope.\nVerification\nThe requirement must be verifiable, and the verification must result in a “fail”or “pass”decision.\nStandard\nThe ASVS is designed to be a collection of security requirements to be implemented to comply with\nthe standard. This means that requirements are limited to defining the security goal to achieve that.\nOther related information can be built on top of ASVS or linked via mappings.\n10",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 4
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nSpecifically, OWASP has many projects, and the ASVS deliberately avoids overlapping with the con‑\ntent in other projects. For example, developers may have a question, “how do I implement a par‑\nticular requirement in my particular technology or environment,”and this should be covered by the\nCheat Sheet Series project. Verifiers may have a question “how do I test this requirement in this\nenvironment,”and this should be covered by the Web Security Testing Guide project.\nWhilst the ASVS is not just intended for security experts to use, it does expect the reader to have\ntechnical knowledge to understand the content or the ability to research particular concepts.\nRequirement\nThe word requirement is used specifically in the ASVS as it describes what must be achieved to satisfy\nit. The ASVS only contains requirements (must) and does not contain recommendations (should) as\nthe main condition.\nIn other words, recommendations, whether they are just one of many possible options to solve a\nproblem or code style considerations, do not satisfy the definition to be a requirement.\nASVS requirements are intended to address specific security principles without being too implemen‑\ntation or technology‑specific, at the same time, being self‑explanatory as to why they exist. This also\nmeans that requirements are not built around a particular verification method or implementation.\nDocumented security decisions\nIn software security, planning security design and the mechanisms to be used early on will lead to a\nmore consistent and reliable implementation in the finished product or feature.\nAdditionally, for certain requirements, implementation will be complicated and very specific to an\napplication’s needs. Common examples include permissions, input validation, and protective con‑\ntrols around different levels of sensitive data.\nTo account for this, rather than sweeping statements like “all data must be encrypted”or trying to\ncover every possible use case in a requirement, documentation requirements were included which\nmandate that the application developer’s approach and configuration to these sorts of controls must\nbe documented. This can then be reviewed for appropriateness and then the actual implementa‑\ntion can be compared to the documentation to assess whether the implementation matches expec‑\ntations.\nThese requirements are intended to document the decisions which the organization developing the\napplication has taken regarding how to implement certain security requirements.\nDocumentation requirements are always in the first section of a chapter (although not every chapter\nhas them) and always have a related implementation requirement where the decisions that are doc‑\numented should actually be put into place. The point here is that verifying that the documentation\nis in place and that the actual implementation are two separate activities.\n11",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 5
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nThere are two key drivers for including these requirements. The first driver is that a security require‑\nment will often involve enforcing rules e.g., what kind of file types are allowed to be uploaded, what\nbusiness controls should be enforced, what are the allowed characters for a particular field. These\nrules will differ for every application, and therefore, the ASVS cannot prescriptively define what they\nshould be, nor will a cheat sheet or more detailed response help in this case. Similarly, without these\ndecisions being documented, it will not be possible to perform verification of the requirements that\nimplement these decisions.\nThe second driver is that for certain requirements, it is important to provide an application devel‑\nopment with flexibility regarding how to address particular security challenges. For example, in\nprevious ASVS versions, session timeout rules were very prescriptive. Practically speaking, many\napplications, especially those that are consumer‑facing, have much more relaxed rules and prefer\nto implement other mitigation controls instead. Documentation requirements, therefore, explicitly\nallow for flexibility around this.\nClearly, it is not expected that individual developers will be making and documenting these decisions\nbut rather the organization as a whole will be taking those decisions and making sure that they are\ncommunicated to developers who then make sure to follow them.\nProviding developers with specifications and designs for new features and functionality is a standard\npart of software development. Similarly, developers are expected to use common components and\nuser interface mechanisms rather than just making their own decisions each time. As such, extend‑\ning this to security should not be seen as surprising or controversial.\nThere is also flexibility around how to achieve this. Security decisions might be documented in a\nliteral document, which developers are expected to refer to. Alternatively, security decisions could\nbe documented and implemented in a common code library that all developers are mandated to use.\nIn both cases, the desired result is achieved.\nApplication Security Verification Levels\nThe ASVS defines three security verification levels, with each level increasing in depth and complex‑\nity. The general aim is for organizations to start with the first level to address the most critical security\nconcerns, and then move up to the higher levels according to the organization and application needs.\nLevels may be presented as L1, L2, and L3 in the document and in requirement texts.\nEach ASVS level indicates the security requirements that are required to achieve from that level, with\nthe higher remaining level requirements as recommendations.\nIn order to avoid duplicate requirements or requirements that are no longer relevant at higher levels,\nsome requirements apply to a particular level but have more stringent conditions for higher levels.\n12",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 6
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nLevel evaluation\nLevels are defined by priority‑based evaluation of each requirement based on experience implement‑\ning and testing security requirements. The main focus is on comparing risk reduction with the effort\nto implement the requirement. Another key factor is to keep a low barrier to entry.\nRisk reduction considers the extent to which the requirement reduces the level of security risk within\nthe application, taking into account the classic Confidentiality, Integrity, and Availability impact fac‑\ntors as well as considering whether this is a primary layer of defense or whether it would be consid‑\nered defense in depth.\nThe rigorous discussions around both the criteria and the leveling decisions have resulted in an al‑\nlocation which should hold true for the vast majority of cases, whilst accepting that it may not be a\n100% fit for every situation. This means that in certain cases, organizations may wish to prioritize\nrequirements from a higher level earlier on based on their own specific risk considerations.\nThe types of requirements in each level could be characterized as follows.\nLevel 1\nThis level contains the minimum requirements to consider when securing an application and rep‑\nresents a critical starting point. This level contains around 20% of the ASVS requirements. The goal\nfor this level is to have as few requirements as possible, to decrease the barrier to entry.\nThese requirements are generally critical or basic, first‑layer of defense requirements for preventing\ncommon attacks that do not require other vulnerabilities or preconditions to be exploitable.\nIn addition to the first layer of defense requirements, some requirements have less of an impact at\nhigher levels, such as requirements related to passwords. Those are more important for Level 1, as\nfrom higher levels, the multi‑factor authentication requirements become relevant.\nLevel 1 is not necessarily penetration testable by an external tester without internal access to docu‑\nmentation or code (such as “black box”testing), although the lower number of requirements should\nmake it easier to verify.\nLevel 2\nMost applications should be striving to achieve this level of security. Around 50% of the requirements\nin the ASVS are L2 meaning that an application needs to implement around 70% of the requirements\nin the ASVS (all of the L1 and L2 requirements) in order to comply with L2.\nThese requirements generally relate to either less common attacks or more complicated protections\nagainst common attacks. They may still be a first layer of defense, or they may require certain pre‑\nconditions for the attack to be successful.\n13",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 7
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nLevel 3\nThis level should be the goal for applications looking to demonstrate the highest levels of security\nand provides the final ~30% of requirements to comply with.\nRequirements in this section are generally either defense‑in‑depth mechanisms or other useful but\nhard‑to‑implement controls.\nWhich level to achieve\nThe priority‑based levels are intended to provide a reflection of the application security maturity\nof the organization and the application. Rather than the ASVS prescriptively stating what level an\napplication should be at, an organization should analyze its risks and decide what level it believes it\nshould be at, depending on the sensitivity of the application and of course, the expectations of the\napplication’s users.\nFor example, an early‑stage startup that is only collecting limited sensitive data may decide to focus\non Level 1 for its initial security goals, but a bank may have difficulty justifying anything less than\nLevel 3 to its customers for its online banking application.\nHow to use the ASVS\nThe structure of the ASVS\nThe ASVS is made up of a total of around 350 requirements which are divided into 17 chapters, each\nof which is further divided into sections.\nThe aim of the chapter and section division is to simplify choosing or filtering out chapters and sec‑\ntions based on the what is relevant for the application. For example, for a machine‑to‑machine API,\nthe requirements in chapter V3 related to web frontends will not be relevant. If there is no use of\nOAuth or WebRTC, then those chapters can be ignored as well.\nRelease strategy\nASVS releases follow the pattern “Major.Minor.Patch”and the numbers provide information on what\nhas changed within the release. In a major release, the first number will change, in a minor release,\nthe second number will change, and in a patch release, the third number will change.\n• Major release ‑ Full reorganization, almost everything may have changed, including require‑\nment numbers. Reevaluation for compliance will be necessary (for example, 4.0.3 ‑> 5.0.0).\n• Minor release ‑ Requirements may be added or removed, but overall numbering will stay the\nsame. Reevaluation for compliance will be necessary, but should be easier (for example, 5.0.0\n‑> 5.1.0).\n14",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 8
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• Patch release ‑ Requirements may be removed (for example, if they are duplicates or outdated)\nor made less stringent, but an application that complied with the previous release will comply\nwith the patch release as well (for example, 5.0.0 ‑> 5.0.1).\nThe above specifically relates to the requirements in the ASVS. Changes to surrounding text and other\ncontent such as the appendices will not be considered to be a breaking change.\nFlexibility with the ASVS\nSeveral of the points described above, such as documentation requirements and the levels mecha‑\nnism, provide the ability to use the ASVS in a more flexible and organization‑specific way.\nAdditionally, organizations are strongly encouraged to create an organization‑ or domain‑specific\nfork that adjusts requirements based on the specific characteristics and risk levels of their applica‑\ntions. However, it is important to maintain traceability so that passing requirement 4.1.1 means the\nsame across all versions.\nIdeally, each organization should create its own tailored ASVS, omitting irrelevant sections (e.g.,\nGraphQL, WebSockets, SOAP, if unused). An organization‑specific ASVS version or supplement is\nalso a good place to provide organization‑specific implementation guidance, detailing libraries or\nresources to use when complying with requirements.\nHow to Reference ASVS Requirements\nEach requirement has an identifier in the format <chapter>.<section>.<requirement>, where each\nelement is a number. For example, 1.11.3.\n• The <chapter> value corresponds to the chapter from which the requirement comes; for ex‑\nample, all 1.#.# requirements are from the ‘Encoding and Sanitization’chapter.\n• The <section> value corresponds to the section within that chapter where the requirement\nappears, for example: all 1.2.# requirements are in the ‘Injection Prevention’section of the\n‘Encoding and Sanitization’chapter.\n• The <requirement> value identifies the specific requirement within the chapter and section,\nfor example, 1.2.5 which as of version 5.0.0 of this standard is:\nVerify that the application protects against OS command injection and that operating system\ncalls use parameterized OS queries or use contextual command line output encoding.\nSince the identifiers may change between versions of the standard, it is preferable for other docu‑\nments, reports, or tools to use the following format: v<version>-<chapter>.<section>.<requirement>,\nwhere: ‘version’is the ASVS version tag. For example: v5.0.0-1.2.5 would be understood to mean\nspecifically the 5th requirement in the ‘Injection Prevention’section of the ‘Encoding and Sanitiza‑\ntion’chapter from version 5.0.0. (This could be summarized as v<version>-<requirement_identifier>.)\n15",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 9
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nNote: The v preceding the version number in the format should always be lowercase.\nIf identifiers are used without including the v<version> element then they should be assumed to\nrefer to the latest Application Security Verification Standard content. As the standard grows and\nchanges this becomes problematic, which is why writers or developers should include the version\nelement.\nASVS requirement lists are made available in CSV, JSON, and other formats which may be useful for\nreference or programmatic use.\nForking the ASVS\nOrganizations can benefit from adopting ASVS by choosing one of the three levels or by creating a\ndomain‑specific fork that adjusts requirements per application risk level. This type of fork is encour‑\naged, provided that it maintains traceability so that passing requirement 4.1.1 means the same across\nall versions.\nIdeally, each organization should create its own tailored ASVS, omitting irrelevant sections (e.g.,\nGraphQL, Websockets, SOAP, if unused). Forking should start with ASVS Level 1 as a baseline, ad‑\nvancing to Levels 2 or 3 based on the application’s risk.\nUse cases for the ASVS\nThe ASVS can be used to assess the security of an application and this is explored in more depth in\nthe next chapter. However, several other potential uses for the ASVS (or a forked version) have been\nidentified.\nAs Detailed Security Architecture Guidance\nOne of the more common uses for the Application Security Verification Standard is as a resource\nfor security architects. There are limited resources available for how to build a secure application\narchiecture, especially with modern applications. ASVS can be used to fill in those gaps by allowing\nsecurity architects to choose better controls for common problems, such as data protection patterns\nand input validation strategies. The architecture and documentation requirements will be particu‑\nlarly useful for this.\nAs a Specialized Secure Coding Reference\nThe ASVS can be used as a basis for preparing a secure coding reference during application devel‑\nopment, helping developers to make sure that they keep security in mind when they build software.\nWhilst the ASVS can be the base, prganizations should prepare their own specific guidance which\nis clear and unified and ideally be prepared based on guidance from security engineers or security\n16",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 10
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\narchitects. As an extension to this, organizations are encouraged wherever possible to prepare ap‑\nproved security mechanisms and libraries that can be referenced in the guidance and used by devel‑\nopers.\nAs a Guide for Automated Unit and Integration Tests\nThe ASVS is designed to be highly testable. Some verifications will be technical where as other re‑\nquirements (such as the architectural and documentation requirements) may require documentation\nor architecture review. By building unit and integration tests that test and fuzz for specific and rele‑\nvant abuse cases related to the requirements that are verifiable by technical means, it should be easier\nto check that these controls are operating correctly on each build. For example, additional tests can\nbe crafted for the test suite for a login controller, testing the username parameter for common de‑\nfault usernames, account enumeration, brute forcing, LDAP and SQL injection, and XSS. Similarly,\na test on the password parameter should include common passwords, password length, null byte\ninjection, removing the parameter, XSS, and more.\nFor Secure Development Training\nASVS can also be used to define the characteristics of secure software. Many “secure coding”courses\nare simply ethical hacking courses with a light smear of coding tips. This may not necessarily help\ndevelopers to write more secure code. Instead, secure development courses can use the ASVS with a\nstrong focus on the positive mechanisms found in the ASVS, rather than the Top 10 negative things\nnot to do. The ASVS structure also provides a logical structure for walking through the different topics\nwhen securing an application.\nAs a Framework for Guiding the Procurement of Secure Software\nThe ASVS is a great framework to help with secure software procurement or procurement of custom\ndevelopment services. The buyer can simply set a requirement that the software they wish to procure\nmust be developed at ASVS level X, and request that the seller proves that the software satisfies ASVS\nlevel X.\nApplying ASVS in Practice\nDifferent threats have different motivations. Some industries have unique information and technol‑\nogy assets and domain‑specific regulatory compliance requirements.\nOrganizations are strongly encouraged to look deeply at their unique risk characteristics based on\nthe nature of their business, and based upon that risk and business requirements determine the\nappropriate ASVS level.\n17",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 11
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nAssessment and Certification\nOWASP’s Stance on ASVS Certifications and Trust Marks\nOWASP, as a vendor‑neutral nonprofit, does not certify any vendors, verifiers, or software. Any as‑\nsurance, trust mark, or certification claiming ASVS compliance is not officially endorsed by OWASP,\nso organizations should be cautious of third‑party claims of ASVS certification.\nOrganizations may offer assurance services, provided they do not claim official OWASP certifica‑\ntion.\nHow to Verify ASVS Compliance\nThe ASVS is deliberately not presciptive about exactly how to verify compliance at the level of a testing\nguide. However, it is important to highlight some key points.\nVerification reporting\nTraditional penetration testing reports issues “by exception,”only listing failures. However, an ASVS\ncertification report should include scope, a summary of all requirements checked, the requirements\nwhere execptions were noted, and guidance on resolving issues. Some requirements may be non‑\napplicable (e.g., session management in stateless APIs), and this must be noted in the report.\nScope of Verification\nAn organization developing an application will generally not implement all requirements, as some\nmay be irrelevant or less significant based on the functionality of the application. The verifier should\nmake the scope of the verification clear including which Level the organization is attempting to\nachieve and which requirements were included. This should be from the perspective of what was\nincluded rather than what was not included. They should also provide an opinion on the rationale of\nexcluding the requirements which haven’t been implemented.\nThis should allow the consumer of a verification report to understand the context of the verification\nand make an informed decision about the level of trust they can place in the application.\nCertifying organizations can choose their testing methods but should disclose them in the report and\nthis should ideally be repeatable. Different methods, like manual penetration tests or source code\nanalysis, may be used to verify aspects such as input validation, depending on the application and\nrequirements.\n18",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 12
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nVerification Mechanisms\nThere are a number of different techniques which may be needed to verify specific ASVS require‑\nments. Aside from penetration testing (using valid credentials to get full application coverage), veri‑\nfying ASVS requirements may require access to documentation, source code, configuration, and the\npeople involved in the development process. Especially for verifying L2 and L3 requirements. It is\nstandard practice to provide robust evidence of findings with detailed documentation, which may in‑\nclude work papers, screenshots, scripts, and testing logs. Merely running an automated tool without\nthorough testing is insufficient for certification, as each requirement must be verifiably tested.\nThe use of automation to verify ASVS requirements is a topic that is constantly of interest. It is there‑\nfore important to clarify some points related to automated and black box testing.\nThe Role of Automated Security Testing Tools\nWhen automated security testing tools such as Dynamic\nand Static Application Security Testing tools (DAST and SAST) are correctly implemented in the build\npipeline, they may be able to identify some security issues that should never exist. However, without\ncareful configuration and tuning they will not provide the required coverage and the level of noise\nwill prevent real security issues from being identified and mitigated.\nWhilst this may provide coverage of some of the more basic and straightforward technical require‑\nments such as those relating to output encoding or sanitiation, it is critical to note that these tools will\nbe unable entirely to verify many of the more complicated ASVS requirements or those that relate to\nbusiness logic and access control.\nFor less straightforward requirements, it is likely that automation can still be utilized but application\nspecific verifications will need to be written to achieve this. These may be similar to unit and integra‑\ntion tests that the organization may already be using. It may therefore be possible to use this existing\ntest automation infrastructure to write these ASVS specific tests. Whilst doing this will require short\nterm investment, the long term benefits being able to continually verify these ASVS requirements\nwill be significant.\nIn summary, testable using automation != running an off the shelf tool.\nThe Role of Penetration Testing\nWhilst L1 in version 4.0 was optimized for “black box”(no documen‑\ntation and no source) testing to occur, even then the standard was clear that it is not an effective\nassurance activity and should be actively discouraged.\nTesting without access to necessary additional information is an inefficient and ineffective mecha‑\nnism for security verification, as it misses out on the possibility of reviewing the source, identifying\nthreats and missing controls, and performing a far more thorough test in a shorter timeframe.\nIt is strongly encouraged to perform documentation or source code‑led (hybrid) penetration testing,\nwhich have full access to the application developers and the application’s documentation, rather\nthan traditional penetration tests. This will certainly be necessary in order to verify many of the\nASVS requirements.\n19",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 13
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nChanges Compared to v4.x\nIntroduction\nUsers familiar with version 4.x of the standard may find it helpful to review the key changes intro‑\nduced in version 5.0, including updates in content, scope, and underlying philosophy.\nOf the 286 requirements in version 4.0.3, only 11 remain unchanged, while 15 have undergone minor\ngrammatical adjustments without altering their meaning. In total 109 requirements (38%) are no\nlonger separate requirements in version 5.0 with 50 simply being deleted, 28 removed as duplicates\nand 31 merged into other requirements. The rest have been revised in some way. Even requirements\nthat were not substantively modified have different identifiers due to reordering or restructuring.\nTo facilitate adoption of version 5.0, mapping documents are provided to help users trace how re‑\nquirements from version 4.x correspond to those in version 5.0. These mappings are not tied to\nrelease versioning and may be updated or clarified as needed.\nRequirement Philosophy\nScope and Focus\nVersion 4.x included requirements that did not align with the intended scope of the standard; these\nhave been removed. Requirements that did not meet the scope criteria for 5.0 or were not verifiable\nhave also been excluded.\nEmphasis on Security Goals Over Mechanisms\nIn version 4.x, many requirements focused on specific mechanisms rather than the underlying se‑\ncurity objectives. In version 5.0, requirements are centered on security goals, referencing particular\nmechanisms only when they are the sole practical solution, or providing them as examples or sup‑\nplementary guidance.\nThis approach recognizes that multiple methods may exist to achieve a given security objective, and\navoids unnecessary prescriptiveness that could limit organizational flexibility.\nAdditionally, requirements addressing the same security concern have been consolidated where ap‑\npropriate.\nDocumented Security Decisions\nWhile the concept of documented security decisions may appear new in version 5.0, it is an evolution\nof earlier requirements related to policy application and threat modeling in version 4.0. Previously,\nsome requirements implicitly demanded analysis to inform the implementation of security controls,\nsuch as determining permitted network connections.\n20",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 14
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nTo ensure that necessary information is available for implementation and verification, these expec‑\ntations are now explicitly defined as documentation requirements, making them clear, actionable,\nand verifiable.\nStructural Changes and New Chapters\nSeveral chapters in version 5.0 introduce entirely new content:\n• OAuth and OIDC –Given the widespread adoption of these protocols for access delegation and\nsingle sign‑on, dedicated requirements have been added to address the diverse scenarios de‑\nvelopers may encounter. This area may eventually evolve into a standalone standard, similar\nto the treatment of Mobile and IoT requirements in previous versions.\n• WebRTC –As this technology gains popularity, its unique security considerations and challenges\nare now addressed in a dedicated section.\nEfforts have also been made to ensure that chapters and sections are organized around coherent sets\nof related requirements.\nThis restructuring has led to the creation of additional chapters:\n• Self‑contained Tokens –Formerly grouped under session management, self‑contained tokens\nare now recognized as a distinct mechanism and a foundational element for stateless com‑\nmunication (such as in OAuth and OIDC). Due to their unique security implications, they are\naddressed in a dedicated chapter, with some new requirements introduced in version 5.x.\n• Web Frontend Security –With the increasing complexity of browser‑based applications and the\nrise of API‑only architectures, frontend security requirements have been separated into their\nown chapter.\n• Secure Coding and Architecture –New requirements addressing general security practices that\ndid not fit within existing chapters have been grouped here.\nOther organizational changes in version 5.0 were made to clarify intent. For example, input valida‑\ntion requirements were moved alongside business logic, reflecting their role in enforcing business\nrules, rather than being grouped with sanitization and encoding.\nThe former V1 Architecture chapter has been removed. Its initial section contained requirements\nthat were out of scope, while subsequent sections have been redistributed to relevant chapters, with\nrequirements deduplicated and clarified as necessary.\nRemoval of Direct Mappings to Other Standards\nDirect mappings to other standards have been removed from the main body of the standard. The aim\nis to prepare a mapping with the OWASP Common Requirement Enumeration (CRE) project, which\nin turn will link ASVS to a range of OWASP projects and external standards.\nDirect mappings to CWE and NIST are no longer maintained, as explained below.\n21",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 15
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nReduced Coupling with NIST Digital Identity Guidelines\nThe NIST Digital Identity Guidelines (SP 800‑63) have long served as a reference for authentication\nand authorization controls. In version 4.x, certain chapters were closely aligned with NIST’s struc‑\nture and terminology.\nWhile these guidelines remain an important reference, strict alignment introduced challenges, in‑\ncluding less widely recognized terminology, duplication of similar requirements, and incomplete\nmappings. Version 5.0 moves away from this approach to improve clarity and relevance.\nMoving Away from Common Weakness Enumeration (CWE)\nThe Common Weakness Enumeration (CWE) provides a useful taxonomy of software security weak‑\nnesses. However, challenges such as category‑only CWEs, difficulties in mapping requirements to\na single CWE, and the presence of imprecise mappings in version 4.x have led to the decision to\ndiscontinue direct CWE mappings in version 5.0.\nRethinking Level Definitions\nVersion 4.x described the levels as L1 (“Minimum”), L2 (“Standard”), and L3 (“Advanced”), with the\nimplication that all applications handling sensitive data should meet at least L2.\nVersion 5.0 addresses several issues with this approach which are described in the following para‑\ngraphs.\nAs a practical matter, whereas version 4.x used tick marks for level indicators, 5.x uses a simple\nnumber on all formats of the standard including markdown, PDF, DOCX, CSV, JSON and XML. For\nbackwards compatibility, legacy versions of the CSV, JSON and XML outputs which still use tick marks\nare also generated.\nEasier Entry Level\nFeedback indicated that the large number of Level 1 requirements (~120), combined with its desig‑\nnation as the “minimum”level that is not good enough for most applications, discouraged adoption.\nVersion 5.0 aims to lower this barrier by defining Level 1 primarily around first‑layer defense require‑\nments, resulting in clearer and fewer requirements at that level. To demonstrate this numerically, in\nv4.0.3 there were 128 L1 requirements out of a total of 278 requirements, representing 46%. In 5.0.0\nthere are 70 L1 requirements out of a total of 345 requirements, representing 20%.\nThe Fallacy of Testability\nA key factor in selecting controls for Level 1 in version 4.x was their suitability for assessment through\n“black box”external penetration testing. However, this approach was not fully aligned with the intent\n22",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 16
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nof Level 1 as the minimum set of security controls. Some users argued that Level 1 was insufficient\nfor securing applications, while others found it too difficult to test.\nRelying on testability as a criterion is both relative and, at times, misleading. The fact that a require‑\nment is testable does not guarantee that it can be tested in an automated or straightforward manner.\nMoreover, the most easily testable requirements are not always those with the greatest security im‑\npact or the simplest to implement.\nAs such, in version 5.0, the level decisions were made primarily based on risk reduction and also\nkeeping in mind the effort to implement.\nNot Just About Risk\nThe use of prescriptive, risk‑based levels that mandate a specific level for certain applications has\nproven to be overly rigid. In practice, the prioritization and implementation of security controls\ndepend on multiple factors, including both risk reduction and the effort required for implementa‑\ntion.\nTherefore, organizations are encouraged to achieve the level that they feel like they should be achiev‑\ning based on their maturity and the message they want to send to their users.\nV1 Encoding and Sanitization\nControl Objective\nThis chapter addresses the most common web application security weaknesses related to the unsafe\nprocessing of untrusted data. Such weaknesses can result in various technical vulnerabilities, where\nuntrusted data is interpreted according to the syntax rules of the relevant interpreter.\nFor modern web applications, it is always best to use safer APIs, such as parameterized queries, auto‑\nescaping, or templating frameworks. Otherwise, carefully performed output encoding, escaping, or\nsanitization becomes critical to the application’s security.\nInput validation serves as a defense‑in‑depth mechanism to protect against unexpected or dangerous\ncontent. However, since its primary purpose is to ensure that incoming content matches functional\nand business expectations, requirements related to this can be found in the “Validation and Business\nLogic”chapter.\nV1.1 Encoding and Sanitization Architecture\nIn the sections below, syntax‑specific or interpreter‑specific requirements for safely processing un‑\nsafe content to avoid security vulnerabilities are provided. The requirements in this section cover\nthe order in which this processing should occur and where it should take place. They also aim to\n23",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 17
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nensure that whenever data is stored, it remains in its original state and is not stored in an encoded or\nescaped form (e.g., HTML encoding), to prevent double encoding issues.\n#\nDescription\nLevel\n1.1.1\nVerify that input is decoded or unescaped into a canonical form only once, it\nis only decoded when encoded data in that form is expected, and that this is\ndone before processing the input further, for example it is not performed\nafter input validation or sanitization.\n2\n1.1.2\nVerify that the application performs output encoding and escaping either as\na final step before being used by the interpreter for which it is intended or by\nthe interpreter itself.\n2\nV1.2 Injection Prevention\nOutput encoding or escaping, performed close to or adjacent to a potentially dangerous context, is\ncritical to the security of any application. Typically, output encoding and escaping are not persisted,\nbut are instead used to render output safe for immediate use in the appropriate interpreter. Attempt‑\ning to perform this too early may result in malformed content or render the encoding or escaping\nineffective.\nIn many cases, software libraries include safe or safer functions that perform this automatically,\nalthough it is necessary to ensure that they are correct for the current context.\n#\nDescription\nLevel\n1.2.1\nVerify that output encoding for an HTTP response, HTML document, or XML\ndocument is relevant for the context required, such as encoding the relevant\ncharacters for HTML elements, HTML attributes, HTML comments, CSS, or\nHTTP header fields, to avoid changing the message or document structure.\n1\n1.2.2\nVerify that when dynamically building URLs, untrusted data is encoded\naccording to its context (e.g., URL encoding or base64url encoding for query\nor path parameters). Ensure that only safe URL protocols are permitted (e.g.,\ndisallow javascript: or data:).\n1\n1.2.3\nVerify that output encoding or escaping is used when dynamically building\nJavaScript content (including JSON), to avoid changing the message or\ndocument structure (to avoid JavaScript and JSON injection).\n1\n24",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 18
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n1.2.4\nVerify that data selection or database queries (e.g., SQL, HQL, NoSQL,\nCypher) use parameterized queries, ORMs, entity frameworks, or are\notherwise protected from SQL Injection and other database injection attacks.\nThis is also relevant when writing stored procedures.\n1\n1.2.5\nVerify that the application protects against OS command injection and that\noperating system calls use parameterized OS queries or use contextual\ncommand line output encoding.\n1\n1.2.6\nVerify that the application protects against LDAP injection vulnerabilities, or\nthat specific security controls to prevent LDAP injection have been\nimplemented.\n2\n1.2.7\nVerify that the application is protected against XPath injection attacks by\nusing query parameterization or precompiled queries.\n2\n1.2.8\nVerify that LaTeX processors are configured securely (such as not using the “–\nshell‑escape”flag) and an allowlist of commands is used to prevent LaTeX\ninjection attacks.\n2\n1.2.9\nVerify that the application escapes special characters in regular expressions\n(typically using a backslash) to prevent them from being misinterpreted as\nmetacharacters.\n2\n1.2.10\nVerify that the application is protected against CSV and Formula Injection.\nThe application must follow the escaping rules defined in RFC 4180 sections\n2.6 and 2.7 when exporting CSV content. Additionally, when exporting to CSV\nor other spreadsheet formats (such as XLS, XLSX, or ODF), special characters\n(including ‘=’, ‘+’, ‘‑’, ‘@’, ‘\\t’(tab), and ‘\\0’(null character)) must be escaped\nwith a single quote if they appear as the first character in a field value.\n3\nNote: Using parameterized queries or escaping SQL is not always sufficient. Query parts such as table\nand column names (including “ORDER BY”column names) cannot be escaped. Including escaped\nuser‑supplied data in these fields results in failed queries or SQL injection.\nV1.3 Sanitization\nThe ideal protection against using untrusted content in an unsafe context is to use context‑specific\nencoding or escaping, which maintains the same semantic meaning of the unsafe content but renders\nit safe for use in that particular context, as discussed in more detail in the previous section.\nWhere this is not possible, sanitization becomes necessary, removing potentially dangerous charac‑\nters or content. In some cases, this may change the semantic meaning of the input, but for security\n25",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 19
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nreasons, there may be no alternative.\n#\nDescription\nLevel\n1.3.1\nVerify that all untrusted HTML input from WYSIWYG editors or similar is\nsanitized using a well‑known and secure HTML sanitization library or\nframework feature.\n1\n1.3.2\nVerify that the application avoids the use of eval() or other dynamic code\nexecution features such as Spring Expression Language (SpEL). Where there\nis no alternative, any user input being included must be sanitized before\nbeing executed.\n1\n1.3.3\nVerify that data being passed to a potentially dangerous context is sanitized\nbeforehand to enforce safety measures, such as only allowing characters\nwhich are safe for this context and trimming input which is too long.\n2\n1.3.4\nVerify that user‑supplied Scalable Vector Graphics (SVG) scriptable content is\nvalidated or sanitized to contain only tags and attributes (such as draw\ngraphics) that are safe for the application, e.g., do not contain scripts and\nforeignObject.\n2\n1.3.5\nVerify that the application sanitizes or disables user‑supplied scriptable or\nexpression template language content, such as Markdown, CSS or XSL\nstylesheets, BBCode, or similar.\n2\n1.3.6\nVerify that the application protects against Server‑side Request Forgery\n(SSRF) attacks, by validating untrusted data against an allowlist of protocols,\ndomains, paths and ports and sanitizing potentially dangerous characters\nbefore using the data to call another service.\n2\n1.3.7\nVerify that the application protects against template injection attacks by not\nallowing templates to be built based on untrusted input. Where there is no\nalternative, any untrusted input being included dynamically during template\ncreation must be sanitized or strictly validated.\n2\n1.3.8\nVerify that the application appropriately sanitizes untrusted input before use\nin Java Naming and Directory Interface (JNDI) queries and that JNDI is\nconfigured securely to prevent JNDI injection attacks.\n2\n1.3.9\nVerify that the application sanitizes content before it is sent to memcache to\nprevent injection attacks.\n2\n1.3.10\nVerify that format strings which might resolve in an unexpected or malicious\nway when used are sanitized before being processed.\n2\n1.3.11\nVerify that the application sanitizes user input before passing to mail\nsystems to protect against SMTP or IMAP injection.\n2\n26",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 20
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n1.3.12\nVerify that regular expressions are free from elements causing exponential\nbacktracking, and ensure untrusted input is sanitized to mitigate ReDoS or\nRunaway Regex attacks.\n3\nV1.4 Memory, String, and Unmanaged Code\nThe following requirements address risks associated with unsafe memory use, which generally apply\nwhen the application uses a systems language or unmanaged code.\nIn some cases, it may be possible to achieve this by setting compiler flags that enable buffer overflow\nprotections and warnings, including stack randomization and data execution prevention, and that\nbreak the build if unsafe pointer, memory, format string, integer, or string operations are found.\n#\nDescription\nLevel\n1.4.1\nVerify that the application uses memory‑safe string, safer memory copy and\npointer arithmetic to detect or prevent stack, buffer, or heap overflows.\n2\n1.4.2\nVerify that sign, range, and input validation techniques are used to prevent\ninteger overflows.\n2\n1.4.3\nVerify that dynamically allocated memory and resources are released, and\nthat references or pointers to freed memory are removed or set to null to\nprevent dangling pointers and use‑after‑free vulnerabilities.\n2\nV1.5 Safe Deserialization\nThe conversion of data from a stored or transmitted representation into actual application objects\n(deserialization) has historically been the cause of various code injection vulnerabilities. It is impor‑\ntant to perform this process carefully and safely to avoid these types of issues.\nIn particular, certain methods of deserialization have been identified by programming language or\nframework documentation as insecure and cannot be made safe with untrusted data. For each mech‑\nanism in use, careful due diligence should be performed.\n#\nDescription\nLevel\n1.5.1\nVerify that the application configures XML parsers to use a restrictive\nconfiguration and that unsafe features such as resolving external entities are\ndisabled to prevent XML eXternal Entity (XXE) attacks.\n1\n27",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 21
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n1.5.2\nVerify that deserialization of untrusted data enforces safe input handling,\nsuch as using an allowlist of object types or restricting client‑defined object\ntypes, to prevent deserialization attacks. Deserialization mechanisms that\nare explicitly defined as insecure must not be used with untrusted input.\n2\n1.5.3\nVerify that different parsers used in the application for the same data type\n(e.g., JSON parsers, XML parsers, URL parsers), perform parsing in a\nconsistent way and use the same character encoding mechanism to avoid\nissues such as JSON Interoperability vulnerabilities or different URI or file\nparsing behavior being exploited in Remote File Inclusion (RFI) or\nServer‑side Request Forgery (SSRF) attacks.\n3\nReferences\nFor more information, see also:\n• OWASP LDAP Injection Prevention Cheat Sheet\n• OWASP Cross Site Scripting Prevention Cheat Sheet\n• OWASP DOM Based Cross Site Scripting Prevention Cheat Sheet\n• OWASP XML External Entity Prevention Cheat Sheet\n• OWASP Web Security Testing Guide: Client‑Side Testing\n• OWASP Java Encoding Project\n• DOMPurify ‑ Client‑side HTML Sanitization Library\n• RFC4180 ‑ Common Format and MIME Type for Comma‑Separated Values (CSV) Files\nFor more information, specifically on deserialization or parsing issues, please see:\n• OWASP Deserialization Cheat Sheet\n• An Exploration of JSON Interoperability Vulnerabilities\n• Orange Tsai ‑ A New Era of SSRF Exploiting URL Parser In Trending Programming Languages\nV2 Validation and Business Logic\nControl Objective\nThis chapter aims to ensure that a verified application meets the following high‑level goals:\n• Input received by the application matches business or functional expectations.\n• The business logic flow is sequential, processed in order, and cannot be bypassed.\n28",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 22
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• Business logic includes limits and controls to detect and prevent automated attacks, such as\ncontinuous small funds transfers or adding a million friends one at a time.\n• High‑value business logic flows have considered abuse cases and malicious actors, and have\nprotections against spoofing, tampering, information disclosure, and elevation of privilege at‑\ntacks.\nV2.1 Validation and Business Logic Documentation\nValidation and business logic documentation should clearly define business logic limits, validation\nrules, and contextual consistency of combined data items, so it is clear what needs to be implemented\nin the application.\n#\nDescription\nLevel\n2.1.1\nVerify that the application’s documentation defines input validation rules for\nhow to check the validity of data items against an expected structure. This\ncould be common data formats such as credit card numbers, email\naddresses, telephone numbers, or it could be an internal data format.\n1\n2.1.2\nVerify that the application’s documentation defines how to validate the\nlogical and contextual consistency of combined data items, such as checking\nthat suburb and ZIP code match.\n2\n2.1.3\nVerify that expectations for business logic limits and validations are\ndocumented, including both per‑user and globally across the application.\n2\nV2.2 Input Validation\nEffective input validation controls enforce business or functional expectations around the type of\ndata the application expects to receive. This ensures good data quality and reduces the attack sur‑\nface. However, it does not remove or replace the need to use correct encoding, parameterization, or\nsanitization when using the data in another component or for presenting it for output.\nIn this context, “input”could come from a wide variety of sources, including HTML form fields, REST\nrequests, URL parameters, HTTP header fields, cookies, files on disk, databases, and external APIs.\nA business logic control might check that a particular input is a number less than 100. A functional\nexpectation might check that a number is below a certain threshold, as that number controls how\nmany times a particular loop will take place, and a high number could lead to excessive processing\nand a potential denial of service condition.\nWhile schema validation is not explicitly mandated, it may be the most effective mechanism for full\nvalidation coverage of HTTP APIs or other interfaces that use JSON or XML.\nPlease note the following points on Schema Validation:\n29",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 23
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• The “published version”of the JSON Schema validation specification is considered production‑\nready, but not strictly speaking “stable.”When using JSON Schema validation, ensure there are\nno gaps with the guidance in the requirements below.\n• Any JSON Schema validation libraries in use should also be monitored and updated if necessary\nonce the standard is formalized.\n• DTD validation should not be used, and framework DTD evaluation should be disabled, to avoid\nissues with XXE attacks against DTDs.\n#\nDescription\nLevel\n2.2.1\nVerify that input is validated to enforce business or functional expectations\nfor that input. This should either use positive validation against an allow list\nof values, patterns, and ranges, or be based on comparing the input to an\nexpected structure and logical limits according to predefined rules. For L1,\nthis can focus on input which is used to make specific business or security\ndecisions. For L2 and up, this should apply to all input.\n1\n2.2.2\nVerify that the application is designed to enforce input validation at a trusted\nservice layer. While client‑side validation improves usability and should be\nencouraged, it must not be relied upon as a security control.\n1\n2.2.3\nVerify that the application ensures that combinations of related data items\nare reasonable according to the pre‑defined rules.\n2\nV2.3 Business Logic Security\nThis section considers key requirements to ensure that the application enforces business logic pro‑\ncesses in the correct way and is not vulnerable to attacks that exploit the logic and flow of the appli‑\ncation.\n#\nDescription\nLevel\n2.3.1\nVerify that the application will only process business logic flows for the same\nuser in the expected sequential step order and without skipping steps.\n1\n2.3.2\nVerify that business logic limits are implemented per the application’s\ndocumentation to avoid business logic flaws being exploited.\n2\n2.3.3\nVerify that transactions are being used at the business logic level such that\neither a business logic operation succeeds in its entirety or it is rolled back to\nthe previous correct state.\n2\n30",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 24
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n2.3.4\nVerify that business logic level locking mechanisms are used to ensure that\nlimited quantity resources (such as theater seats or delivery slots) cannot be\ndouble‑booked by manipulating the application’s logic.\n2\n2.3.5\nVerify that high‑value business logic flows require multi‑user approval to\nprevent unauthorized or accidental actions. This could include but is not\nlimited to large monetary transfers, contract approvals, access to classified\ninformation, or safety overrides in manufacturing.\n3\nV2.4 Anti‑automation\nThis section includes anti‑automation controls to ensure that human‑like interactions are required\nand excessive automated requests are prevented.\n#\nDescription\nLevel\n2.4.1\nVerify that anti‑automation controls are in place to protect against excessive\ncalls to application functions that could lead to data exfiltration,\ngarbage‑data creation, quota exhaustion, rate‑limit breaches,\ndenial‑of‑service, or overuse of costly resources.\n2\n2.4.2\nVerify that business logic flows require realistic human timing, preventing\nexcessively rapid transaction submissions.\n3\nReferences\nFor more information, see also:\n• OWASP Web Security Testing Guide: Input Validation Testing\n• OWASP Web Security Testing Guide: Business Logic Testing\n• Anti‑automation can be achieved in many ways, including the use of the OWASP Automated\nThreats to Web Applications\n• OWASP Input Validation Cheat Sheet\n• JSON Schema\n31",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 25
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nV3 Web Frontend Security\nControl Objective\nThis category focuses on requirements designed to protect against attacks executed via a web fron‑\ntend. These requirements do not apply to machine‑to‑machine solutions.\nV3.1 Web Frontend Security Documentation\nThis section outlines the browser security features that should be specified in the application’s doc‑\numentation.\n#\nDescription\nLevel\n3.1.1\nVerify that application documentation states the expected security features\nthat browsers using the application must support (such as HTTPS, HTTP\nStrict Transport Security (HSTS), Content Security Policy (CSP), and other\nrelevant HTTP security mechanisms). It must also define how the\napplication must behave when some of these features are not available (such\nas warning the user or blocking access).\n3\nV3.2 Unintended Content Interpretation\nRendering content or functionality in an incorrect context can result in malicious content being ex‑\necuted or displayed.\n#\nDescription\nLevel\n3.2.1\nVerify that security controls are in place to prevent browsers from rendering\ncontent or functionality in HTTP responses in an incorrect context (e.g.,\nwhen an API, a user‑uploaded file or other resource is requested directly).\nPossible controls could include: not serving the content unless HTTP request\nheader fields (such as Sec‑Fetch‑*) indicate it is the correct context, using the\nsandbox directive of the Content‑Security‑Policy header field or using the\nattachment disposition type in the Content‑Disposition header field.\n1\n3.2.2\nVerify that content intended to be displayed as text, rather than rendered as\nHTML, is handled using safe rendering functions (such as createTextNode or\ntextContent) to prevent unintended execution of content such as HTML or\nJavaScript.\n1\n32",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 26
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n3.2.3\nVerify that the application avoids DOM clobbering when using client‑side\nJavaScript by employing explicit variable declarations, performing strict type\nchecking, avoiding storing global variables on the document object, and\nimplementing namespace isolation.\n3\nV3.3 Cookie Setup\nThis section outlines requirements for securely configuring sensitive cookies to provide a higher\nlevel of assurance that they were created by the application itself and to prevent their contents from\nleaking or being inappropriately modified.\n#\nDescription\nLevel\n3.3.1\nVerify that cookies have the ‘Secure’attribute set, and if the ’__Host‑’prefix is\nnot used for the cookie name, the ’__Secure‑’prefix must be used for the\ncookie name.\n1\n3.3.2\nVerify that each cookie’s ‘SameSite’attribute value is set according to the\npurpose of the cookie, to limit exposure to user interface redress attacks and\nbrowser‑based request forgery attacks, commonly known as cross‑site\nrequest forgery (CSRF).\n2\n3.3.3\nVerify that cookies have the ’__Host‑’prefix for the cookie name unless they\nare explicitly designed to be shared with other hosts.\n2\n3.3.4\nVerify that if the value of a cookie is not meant to be accessible to client‑side\nscripts (such as a session token), the cookie must have the ‘HttpOnly’\nattribute set and the same value (e. g. session token) must only be\ntransferred to the client via the ‘Set‑Cookie’header field.\n2\n3.3.5\nVerify that when the application writes a cookie, the cookie name and value\nlength combined are not over 4096 bytes. Overly large cookies will not be\nstored by the browser and therefore not sent with requests, preventing the\nuser from using application functionality which relies on that cookie.\n3\nV3.4 Browser Security Mechanism Headers\nThis section describes which security headers should be set on HTTP responses to enable browser\nsecurity features and restrictions when handling responses from the application.\n33",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 27
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n3.4.1\nVerify that a Strict‑Transport‑Security header field is included on all\nresponses to enforce an HTTP Strict Transport Security (HSTS) policy. A\nmaximum age of at least 1 year must be defined, and for L2 and up, the\npolicy must apply to all subdomains as well.\n1\n3.4.2\nVerify that the Cross‑Origin Resource Sharing (CORS)\nAccess‑Control‑Allow‑Origin header field is a fixed value by the application,\nor if the Origin HTTP request header field value is used, it is validated against\nan allowlist of trusted origins. When ’Access‑Control‑Allow‑Origin: *’needs\nto be used, verify that the response does not include any sensitive\ninformation.\n1\n3.4.3\nVerify that HTTP responses include a Content‑Security‑Policy response\nheader field which defines directives to ensure the browser only loads and\nexecutes trusted content or resources, in order to limit execution of\nmalicious JavaScript. As a minimum, a global policy must be used which\nincludes the directives object‑src ‘none’and base‑uri ‘none’and defines either\nan allowlist or uses nonces or hashes. For an L3 application, a per‑response\npolicy with nonces or hashes must be defined.\n2\n3.4.4\nVerify that all HTTP responses contain an ‘X‑Content‑Type‑Options: nosniff’\nheader field. This instructs browsers not to use content sniffing and MIME\ntype guessing for the given response, and to require the response’s\nContent‑Type header field value to match the destination resource. For\nexample, the response to a request for a style is only accepted if the\nresponse’s Content‑Type is ‘text/css’. This also enables the use of the\nCross‑Origin Read Blocking (CORB) functionality by the browser.\n2\n3.4.5\nVerify that the application sets a referrer policy to prevent leakage of\ntechnically sensitive data to third‑party services via the ‘Referer’HTTP\nrequest header field. This can be done using the Referrer‑Policy HTTP\nresponse header field or via HTML element attributes. Sensitive data could\ninclude path and query data in the URL, and for internal non‑public\napplications also the hostname.\n2\n3.4.6\nVerify that the web application uses the frame‑ancestors directive of the\nContent‑Security‑Policy header field for every HTTP response to ensure that\nit cannot be embedded by default and that embedding of specific resources\nis allowed only when necessary. Note that the X‑Frame‑Options header field,\nalthough supported by browsers, is obsolete and may not be relied upon.\n2\n3.4.7\nVerify that the Content‑Security‑Policy header field specifies a location to\nreport violations.\n3\n34",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 28
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n3.4.8\nVerify that all HTTP responses that initiate a document rendering (such as\nresponses with Content‑Type text/html), include the\nCross‑Origin‑Opener‑Policy header field with the same‑origin directive or\nthe same‑origin‑allow‑popups directive as required. This prevents attacks\nthat abuse shared access to Window objects, such as tabnabbing and frame\ncounting.\n3\nV3.5 Browser Origin Separation\nWhen accepting a request to sensitive functionality on the server side, the application needs to ensure\nthe request is initiated by the application itself or by a trusted party and has not been forged by an\nattacker.\nSensitive functionality in this context could include accepting form posts for authenticated\nand non‑authenticated users (such as an authentication request), state‑changing operations, or\nresource‑demanding functionality (such as data export).\nThe key protections here are browser security policies like Same Origin Policy for JavaScript and\nalso SameSite logic for cookies. Another common protection is the CORS preflight mechanism. This\nmechanism will be critical for endpoints designed to be called from a different origin, but it can also\nbe a useful request forgery prevention mechanism for endpoints which are not designed to be called\nfrom a different origin.\n#\nDescription\nLevel\n3.5.1\nVerify that, if the application does not rely on the CORS preflight mechanism\nto prevent disallowed cross‑origin requests to use sensitive functionality,\nthese requests are validated to ensure they originate from the application\nitself. This may be done by using and validating anti‑forgery tokens or\nrequiring extra HTTP header fields that are not CORS‑safelisted\nrequest‑header fields. This is to defend against browser‑based request\nforgery attacks, commonly known as cross‑site request forgery (CSRF).\n1\n3.5.2\nVerify that, if the application relies on the CORS preflight mechanism to\nprevent disallowed cross‑origin use of sensitive functionality, it is not\npossible to call the functionality with a request which does not trigger a\nCORS‑preflight request. This may require checking the values of the ‘Origin’\nand ‘Content‑Type’request header fields or using an extra header field that is\nnot a CORS‑safelisted header‑field.\n1\n35",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 29
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n3.5.3\nVerify that HTTP requests to sensitive functionality use appropriate HTTP\nmethods such as POST, PUT, PATCH, or DELETE, and not methods defined\nby the HTTP specification as “safe”such as HEAD, OPTIONS, or GET.\nAlternatively, strict validation of the Sec‑Fetch‑* request header fields can be\nused to ensure that the request did not originate from an inappropriate\ncross‑origin call, a navigation request, or a resource load (such as an image\nsource) where this is not expected.\n1\n3.5.4\nVerify that separate applications are hosted on different hostnames to\nleverage the restrictions provided by same‑origin policy, including how\ndocuments or scripts loaded by one origin can interact with resources from\nanother origin and hostname‑based restrictions on cookies.\n2\n3.5.5\nVerify that messages received by the postMessage interface are discarded if\nthe origin of the message is not trusted, or if the syntax of the message is\ninvalid.\n2\n3.5.6\nVerify that JSONP functionality is not enabled anywhere across the\napplication to avoid Cross‑Site Script Inclusion (XSSI) attacks.\n3\n3.5.7\nVerify that data requiring authorization is not included in script resource\nresponses, like JavaScript files, to prevent Cross‑Site Script Inclusion (XSSI)\nattacks.\n3\n3.5.8\nVerify that authenticated resources (such as images, videos, scripts, and\nother documents) can be loaded or embedded on behalf of the user only\nwhen intended. This can be accomplished by strict validation of the\nSec‑Fetch‑* HTTP request header fields to ensure that the request did not\noriginate from an inappropriate cross‑origin call, or by setting a restrictive\nCross‑Origin‑Resource‑Policy HTTP response header field to instruct the\nbrowser to block returned content.\n3\nV3.6 External Resource Integrity\nThis section provides guidance for the safe hosting of content on third‑party sites.\n36",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 30
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n3.6.1\nVerify that client‑side assets, such as JavaScript libraries, CSS, or web fonts,\nare only hosted externally (e.g., on a Content Delivery Network) if the\nresource is static and versioned and Subresource Integrity (SRI) is used to\nvalidate the integrity of the asset. If this is not possible, there should be a\ndocumented security decision to justify this for each resource.\n3\nV3.7 Other Browser Security Considerations\nThis section includes various other security controls and modern browser security features required\nfor client‑side browser security.\n#\nDescription\nLevel\n3.7.1\nVerify that the application only uses client‑side technologies which are still\nsupported and considered secure. Examples of technologies which do not\nmeet this requirement include NSAPI plugins, Flash, Shockwave, ActiveX,\nSilverlight, NACL, or client‑side Java applets.\n2\n3.7.2\nVerify that the application will only automatically redirect the user to a\ndifferent hostname or domain (which is not controlled by the application)\nwhere the destination appears on an allowlist.\n2\n3.7.3\nVerify that the application shows a notification when the user is being\nredirected to a URL outside of the application’s control, with an option to\ncancel the navigation.\n3\n3.7.4\nVerify that the application’s top‑level domain (e.g., site.tld) is added to the\npublic preload list for HTTP Strict Transport Security (HSTS). This ensures\nthat the use of TLS for the application is built directly into the main\nbrowsers, rather than relying only on the Strict‑Transport‑Security response\nheader field.\n3\n3.7.5\nVerify that the application behaves as documented (such as warning the user\nor blocking access) if the browser used to access the application does not\nsupport the expected security features.\n3\nReferences\nFor more information, see also:\n• Set‑Cookie __Host‑ prefix details\n37",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 31
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• OWASP Content Security Policy Cheat Sheet\n• OWASP Secure Headers Project\n• OWASP Cross‑Site Request Forgery Prevention Cheat Sheet\n• HSTS Browser Preload List submission form\n• OWASP DOM Clobbering Prevention Cheat Sheet\nV4 API and Web Service\nControl Objective\nSeveral considerations apply specifically to applications that expose APIs for use by web browsers\nor other consumers (commonly using JSON, XML, or GraphQL). This chapter covers the relevant\nsecurity configurations and mechanisms that should be applied.\nNote that authentication, session management, and input validation concerns from other chapters\nalso apply to APIs, so this chapter cannot be taken out of context or tested in isolation.\nV4.1 Generic Web Service Security\nThis section addresses general web service security considerations and, consequently, basic web\nservice hygiene practices.\n#\nDescription\nLevel\n4.1.1\nVerify that every HTTP response with a message body contains a\nContent‑Type header field that matches the actual content of the response,\nincluding the charset parameter to specify safe character encoding (e.g.,\nUTF‑8, ISO‑8859‑1) according to IANA Media Types, such as “text/”, “/+xml”\nand “/xml”.\n1\n4.1.2\nVerify that only user‑facing endpoints (intended for manual web‑browser\naccess) automatically redirect from HTTP to HTTPS, while other services or\nendpoints do not implement transparent redirects. This is to avoid a\nsituation where a client is erroneously sending unencrypted HTTP requests,\nbut since the requests are being automatically redirected to HTTPS, the\nleakage of sensitive data goes undiscovered.\n2\n4.1.3\nVerify that any HTTP header field used by the application and set by an\nintermediary layer, such as a load balancer, a web proxy, or a\nbackend‑for‑frontend service, cannot be overridden by the end‑user.\nExample headers might include X‑Real‑IP, X‑Forwarded‑*, or X‑User‑ID.\n2\n38",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 32
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n4.1.4\nVerify that only HTTP methods that are explicitly supported by the\napplication or its API (including OPTIONS during preflight requests) can be\nused and that unused methods are blocked.\n3\n4.1.5\nVerify that per‑message digital signatures are used to provide additional\nassurance on top of transport protections for requests or transactions which\nare highly sensitive or which traverse a number of systems.\n3\nV4.2 HTTP Message Structure Validation\nThis section explains how the structure and header fields of an HTTP message should be validated to\nprevent attacks such as request smuggling, response splitting, header injection, and denial of service\nvia overly long HTTP messages.\nThese requirements are relevant for general HTTP message processing and generation, but are es‑\npecially important when converting HTTP messages between different HTTP versions.\n#\nDescription\nLevel\n4.2.1\nVerify that all application components (including load balancers, firewalls,\nand application servers) determine boundaries of incoming HTTP messages\nusing the appropriate mechanism for the HTTP version to prevent HTTP\nrequest smuggling. In HTTP/1.x, if a Transfer‑Encoding header field is\npresent, the Content‑Length header must be ignored per RFC 2616. When\nusing HTTP/2 or HTTP/3, if a Content‑Length header field is present, the\nreceiver must ensure that it is consistent with the length of the DATA frames.\n2\n4.2.2\nVerify that when generating HTTP messages, the Content‑Length header\nfield does not conflict with the length of the content as determined by the\nframing of the HTTP protocol, in order to prevent request smuggling attacks.\n3\n4.2.3\nVerify that the application does not send nor accept HTTP/2 or HTTP/3\nmessages with connection‑specific header fields such as Transfer‑Encoding\nto prevent response splitting and header injection attacks.\n3\n4.2.4\nVerify that the application only accepts HTTP/2 and HTTP/3 requests where\nthe header fields and values do not contain any CR (\\r), LF (\\n), or CRLF\n(\\r\\n) sequences, to prevent header injection attacks.\n3\n39",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 33
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n4.2.5\nVerify that, if the application (backend or frontend) builds and sends\nrequests, it uses validation, sanitization, or other mechanisms to avoid\ncreating URIs (such as for API calls) or HTTP request header fields (such as\nAuthorization or Cookie), which are too long to be accepted by the receiving\ncomponent. This could cause a denial of service, such as when sending an\noverly long request (e.g., a long cookie header field), which results in the\nserver always responding with an error status.\n3\nV4.3 GraphQL\nGraphQL is becoming more common as a way of creating data‑rich clients that are not tightly coupled\nto a variety of backend services. This section covers security considerations for GraphQL.\n#\nDescription\nLevel\n4.3.1\nVerify that a query allowlist, depth limiting, amount limiting, or query cost\nanalysis is used to prevent GraphQL or data layer expression Denial of\nService (DoS) as a result of expensive, nested queries.\n2\n4.3.2\nVerify that GraphQL introspection queries are disabled in the production\nenvironment unless the GraphQL API is meant to be used by other parties.\n2\nV4.4 WebSocket\nWebSocket is a communications protocol that provides a simultaneous two‑way communication\nchannel over a single TCP connection. It was standardized by the IETF as RFC 6455 in 2011 and is\ndistinct from HTTP, even though it is designed to work over HTTP ports 443 and 80.\nThis section provides key security requirements to prevent attacks related to communication security\nand session management that specifically exploit this real‑time communication channel.\n#\nDescription\nLevel\n4.4.1\nVerify that WebSocket over TLS (WSS) is used for all WebSocket connections.\n1\n4.4.2\nVerify that, during the initial HTTP WebSocket handshake, the Origin header\nfield is checked against a list of origins allowed for the application.\n2\n40",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 34
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n4.4.3\nVerify that, if the application’s standard session management cannot be\nused, dedicated tokens are being used for this, which comply with the\nrelevant Session Management security requirements.\n2\n4.4.4\nVerify that dedicated WebSocket session management tokens are initially\nobtained or validated through the previously authenticated HTTPS session\nwhen transitioning an existing HTTPS session to a WebSocket channel.\n2\nReferences\nFor more information, see also:\n• OWASP REST Security Cheat Sheet\n• Resources on GraphQL Authorization from graphql.org and Apollo.\n• OWASP Web Security Testing Guide: GraphQL Testing\n• OWASP Web Security Testing Guide: Testing WebSockets\nV5 File Handling\nControl Objective\nThe use of files can present a variety of risks to the application, including denial of service, unautho‑\nrized access, and storage exhaustion. This chapter includes requirements to address these risks.\nV5.1 File Handling Documentation\nThis section includes a requirement to document the expected characteristics of files accepted by the\napplication, as a necessary precondition for developing and verifying relevant security checks.\n#\nDescription\nLevel\n5.1.1\nVerify that the documentation defines the permitted file types, expected file\nextensions, and maximum size (including unpacked size) for each upload\nfeature. Additionally, ensure that the documentation specifies how files are\nmade safe for end‑users to download and process, such as how the\napplication behaves when a malicious file is detected.\n2\n41",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 35
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nV5.2 File Upload and Content\nFile upload functionality is a primary source of untrusted files. This section outlines the require‑\nments for ensuring that the presence, volume, or content of these files cannot harm the applica‑\ntion.\n#\nDescription\nLevel\n5.2.1\nVerify that the application will only accept files of a size which it can process\nwithout causing a loss of performance or a denial of service attack.\n1\n5.2.2\nVerify that when the application accepts a file, either on its own or within an\narchive such as a zip file, it checks if the file extension matches an expected\nfile extension and validates that the contents correspond to the type\nrepresented by the extension. This includes, but is not limited to, checking\nthe initial ‘magic bytes’, performing image re‑writing, and using specialized\nlibraries for file content validation. For L1, this can focus just on files which\nare used to make specific business or security decisions. For L2 and up, this\nmust apply to all files being accepted.\n1\n5.2.3\nVerify that the application checks compressed files (e.g., zip, gz, docx, odt)\nagainst maximum allowed uncompressed size and against maximum\nnumber of files before uncompressing the file.\n2\n5.2.4\nVerify that a file size quota and maximum number of files per user are\nenforced to ensure that a single user cannot fill up the storage with too many\nfiles, or excessively large files.\n3\n5.2.5\nVerify that the application does not allow uploading compressed files\ncontaining symlinks unless this is specifically required (in which case it will\nbe necessary to enforce an allowlist of the files that can be symlinked to).\n3\n5.2.6\nVerify that the application rejects uploaded images with a pixel size larger\nthan the maximum allowed, to prevent pixel flood attacks.\n3\nV5.3 File Storage\nThis section includes requirements to prevent files from being inappropriately executed after upload,\nto detect dangerous content, and to avoid untrusted data being used to control where files are being\nstored.\n42",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 36
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n5.3.1\nVerify that files uploaded or generated by untrusted input and stored in a\npublic folder, are not executed as server‑side program code when accessed\ndirectly with an HTTP request.\n1\n5.3.2\nVerify that when the application creates file paths for file operations, instead\nof user‑submitted filenames, it uses internally generated or trusted data, or if\nuser‑submitted filenames or file metadata must be used, strict validation and\nsanitization must be applied. This is to protect against path traversal, local or\nremote file inclusion (LFI, RFI), and server‑side request forgery (SSRF)\nattacks.\n1\n5.3.3\nVerify that server‑side file processing, such as file decompression, ignores\nuser‑provided path information to prevent vulnerabilities such as zip slip.\n3\nV5.4 File Download\nThis section contains requirements to mitigate risks when serving files to be downloaded, including\npath traversal and injection attacks. This also includes making sure they don’t contain dangerous\ncontent.\n#\nDescription\nLevel\n5.4.1\nVerify that the application validates or ignores user‑submitted filenames,\nincluding in a JSON, JSONP, or URL parameter and specifies a filename in the\nContent‑Disposition header field in the response.\n2\n5.4.2\nVerify that file names served (e.g., in HTTP response header fields or email\nattachments) are encoded or sanitized (e.g., following RFC 6266) to preserve\ndocument structure and prevent injection attacks.\n2\n5.4.3\nVerify that files obtained from untrusted sources are scanned by antivirus\nscanners to prevent serving of known malicious content.\n2\nReferences\nFor more information, see also:\n• OWASP File Upload Cheat Sheet\n• Example of using symlinks for arbitrary file read\n• Explanation of “Magic Bytes”from Wikipedia\n43",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 37
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nV6 Authentication\nControl Objective\nAuthentication is the process of establishing or confirming the authenticity of an individual or device.\nIt involves verifying claims made by a person or about a device, ensuring resistance to impersonation,\nand preventing the recovery or interception of passwords.\nNIST SP 800‑63 is a modern, evidence‑based standard that is valuable for organizations worldwide,\nbut is particularly relevant to US agencies and those interacting with US agencies.\nWhile many of the requirements in this chapter are based on the second section of the standard\n(known as NIST SP 800‑63B “Digital Identity Guidelines ‑ Authentication and Lifecycle Management”\n), the chapter focuses on common threats and frequently exploited authentication weaknesses. It\ndoes not attempt to comprehensively cover every point in the standard. For cases where full NIST SP\n800‑63 compliance is necessary, please refer to NIST SP 800‑63.\nAdditionally, NIST SP 800‑63 terminology may sometimes differ, and this chapter often uses more\ncommonly understood terminology to improve clarity.\nA common feature of more advanced applications is the ability to adapt authentication stages re‑\nquired based on various risk factors. This feature is covered in the “Authorization”chapter, since\nthese mechanisms also need to be considered for authorization decisions.\nV6.1 Authentication Documentation\nThis section contains requirements detailing the authentication documentation that should be main‑\ntained for an application. This is crucial for implementing and assessing how the relevant authenti‑\ncation controls should be configured.\n#\nDescription\nLevel\n6.1.1\nVerify that application documentation defines how controls such as rate\nlimiting, anti‑automation, and adaptive response, are used to defend against\nattacks such as credential stuffing and password brute force. The\ndocumentation must make clear how these controls are configured and\nprevent malicious account lockout.\n1\n6.1.2\nVerify that a list of context‑specific words is documented in order to prevent\ntheir use in passwords. The list could include permutations of organization\nnames, product names, system identifiers, project codenames, department\nor role names, and similar.\n2\n44",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 38
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n6.1.3\nVerify that, if the application includes multiple authentication pathways,\nthese are all documented together with the security controls and\nauthentication strength which must be consistently enforced across them.\n2\nV6.2 Password Security\nPasswords, called “Memorized Secrets”by NIST SP 800‑63, include passwords, passphrases, PINs,\nunlock patterns, and picking the correct kitten or another image element. They are generally con‑\nsidered “something you know”and are often used as a single‑factor authentication mechanism.\nAs such, this section contains requirements for making sure that passwords are created and handled\nsecurely. Most of the requirements are L1 as they are most important at that level. From L2 on‑\nwards, multi‑factor authentication mechanisms are required, where passwords may be one of those\nfactors.\nThe requirements in this section mostly relate to § 5.1.1.2 of NIST’s Guidance.\n#\nDescription\nLevel\n6.2.1\nVerify that user set passwords are at least 8 characters in length although a\nminimum of 15 characters is strongly recommended.\n1\n6.2.2\nVerify that users can change their password.\n1\n6.2.3\nVerify that password change functionality requires the user’s current and\nnew password.\n1\n6.2.4\nVerify that passwords submitted during account registration or password\nchange are checked against an available set of, at least, the top 3000\npasswords which match the application’s password policy, e.g. minimum\nlength.\n1\n6.2.5\nVerify that passwords of any composition can be used, without rules limiting\nthe type of characters permitted. There must be no requirement for a\nminimum number of upper or lower case characters, numbers, or special\ncharacters.\n1\n6.2.6\nVerify that password input fields use type=password to mask the entry.\nApplications may allow the user to temporarily view the entire masked\npassword, or the last typed character of the password.\n1\n6.2.7\nVerify that “paste”functionality, browser password helpers, and external\npassword managers are permitted.\n1\n45",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 39
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n6.2.8\nVerify that the application verifies the user’s password exactly as received\nfrom the user, without any modifications such as truncation or case\ntransformation.\n1\n6.2.9\nVerify that passwords of at least 64 characters are permitted.\n2\n6.2.10\nVerify that a user’s password stays valid until it is discovered to be\ncompromised or the user rotates it. The application must not require\nperiodic credential rotation.\n2\n6.2.11\nVerify that the documented list of context specific words is used to prevent\neasy to guess passwords being created.\n2\n6.2.12\nVerify that passwords submitted during account registration or password\nchanges are checked against a set of breached passwords.\n2\nV6.3 General Authentication Security\nThis section contains general requirements for the security of authentication mechanisms as well as\nsetting out the different expectations for levels. L2 applications must force the use of multi‑factor\nauthentication (MFA). L3 applications must use hardware‑based authentication, performed in an at‑\ntested and trusted execution environment (TEE). This could include device‑bound passkeys, eIDAS\nLevel of Assurance (LoA) High enforced authenticators, authenticators with NIST Authenticator As‑\nsurance Level 3 (AAL3) assurance, or an equivalent mechanism.\nWhile this is a relatively aggressive stance on MFA, it is critical to raise the bar around this to protect\nusers, and any attempt to relax these requirements should be accompanied by a clear plan on how\nthe risks around authentication will be mitigated, taking into account NIST’s guidance and research\non the topic.\nNote that at the time of release, NIST SP 800‑63 considers email as not acceptable as an authentication\nmechanism (archived copy).\nThe requirements in this section relate to a variety of sections of NIST’s Guidance, including: § 4.2.1,\n§ 4.3.1, § 5.2.2, and § 6.1.2.\n#\nDescription\nLevel\n6.3.1\nVerify that controls to prevent attacks such as credential stuffing and\npassword brute force are implemented according to the application’s\nsecurity documentation.\n1\n6.3.2\nVerify that default user accounts (e.g., “root”, “admin”, or “sa”) are not\npresent in the application or are disabled.\n1\n46",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 40
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n6.3.3\nVerify that either a multi‑factor authentication mechanism or a combination\nof single‑factor authentication mechanisms, must be used in order to access\nthe application. For L3, one of the factors must be a hardware‑based\nauthentication mechanism which provides compromise and impersonation\nresistance against phishing attacks while verifying the intent to authenticate\nby requiring a user‑initiated action (such as a button press on a FIDO\nhardware key or a mobile phone). Relaxing any of the considerations in this\nrequirement requires a fully documented rationale and a comprehensive set\nof mitigating controls.\n2\n6.3.4\nVerify that, if the application includes multiple authentication pathways,\nthere are no undocumented pathways and that security controls and\nauthentication strength are enforced consistently.\n2\n6.3.5\nVerify that users are notified of suspicious authentication attempts\n(successful or unsuccessful). This may include authentication attempts from\nan unusual location or client, partially successful authentication (only one of\nmultiple factors), an authentication attempt after a long period of inactivity\nor a successful authentication after several unsuccessful attempts.\n3\n6.3.6\nVerify that email is not used as either a single‑factor or multi‑factor\nauthentication mechanism.\n3\n6.3.7\nVerify that users are notified after updates to authentication details, such as\ncredential resets or modification of the username or email address.\n3\n6.3.8\nVerify that valid users cannot be deduced from failed authentication\nchallenges, such as by basing on error messages, HTTP response codes, or\ndifferent response times. Registration and forgot password functionality\nmust also have this protection.\n3\nV6.4 Authentication Factor Lifecycle and Recovery\nAuthentication factors may include passwords, soft tokens, hardware tokens, and biometric devices.\nSecurely handling the lifecycle of these mechanisms is critical to the security of an application, and\nthis section includes requirements related to this.\nThe requirements in this section mostly relate to § 5.1.1.2 or § 6.1.2.3 of NIST’s Guidance.\n47",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 41
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n6.4.1\nVerify that system generated initial passwords or activation codes are\nsecurely randomly generated, follow the existing password policy, and\nexpire after a short period of time or after they are initially used. These\ninitial secrets must not be permitted to become the long term password.\n1\n6.4.2\nVerify that password hints or knowledge‑based authentication (so‑called\n“secret questions”) are not present.\n1\n6.4.3\nVerify that a secure process for resetting a forgotten password is\nimplemented, that does not bypass any enabled multi‑factor authentication\nmechanisms.\n2\n6.4.4\nVerify that if a multi‑factor authentication factor is lost, evidence of identity\nproofing is performed at the same level as during enrollment.\n2\n6.4.5\nVerify that renewal instructions for authentication mechanisms which expire\nare sent with enough time to be carried out before the old authentication\nmechanism expires, configuring automated reminders if necessary.\n3\n6.4.6\nVerify that administrative users can initiate the password reset process for\nthe user, but that this does not allow them to change or choose the user’s\npassword. This prevents a situation where they know the user’s password.\n3\nV6.5 General Multi‑factor authentication requirements\nThis section provides general guidance that will be relevant to various different multi‑factor authen‑\ntication methods.\nThe mechanisms include:\n• Lookup Secrets\n• Time based One‑time Passwords (TOTPs)\n• Out‑of‑Band mechanisms\nLookup secrets are pre‑generated lists of secret codes, similar to Transaction Authorization Num‑\nbers (TAN), social media recovery codes, or a grid containing a set of random values. This type of\nauthentication mechanism is considered “something you have”because the codes are deliberately\nnot memorable so will need to be stored somewhere.\nTime based One‑time Passwords (TOTPs) are physical or soft tokens that display a continually\nchanging pseudo‑random one‑time challenge. This type of authentication mechanism is considered\n“something you have”. Multi‑factor TOTPs are similar to single‑factor TOTPs, but require a valid\nPIN code, biometric unlocking, USB insertion or NFC pairing, or some additional value (such as\ntransaction signing calculators) to be entered to create the final One‑time Password (OTP).\n48",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 42
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nDetails on out‑of‑band mechanisms will be provided in the next section.\nThe requirements in these sections mostly relate to § 5.1.2, § 5.1.3, § 5.1.4.2, § 5.1.5.2, § 5.2.1, and §\n5.2.3 of NIST’s Guidance.\n#\nDescription\nLevel\n6.5.1\nVerify that lookup secrets, out‑of‑band authentication requests or codes, and\ntime‑based one‑time passwords (TOTPs) are only successfully usable once.\n2\n6.5.2\nVerify that, when being stored in the application’s backend, lookup secrets\nwith less than 112 bits of entropy (19 random alphanumeric characters or 34\nrandom digits) are hashed with an approved password storage hashing\nalgorithm that incorporates a 32‑bit random salt. A standard hash function\ncan be used if the secret has 112 bits of entropy or more.\n2\n6.5.3\nVerify that lookup secrets, out‑of‑band authentication code, and time‑based\none‑time password seeds, are generated using a Cryptographically Secure\nPseudorandom Number Generator (CSPRNG) to avoid predictable values.\n2\n6.5.4\nVerify that lookup secrets and out‑of‑band authentication codes have a\nminimum of 20 bits of entropy (typically 4 random alphanumeric characters\nor 6 random digits is sufficient).\n2\n6.5.5\nVerify that out‑of‑band authentication requests, codes, or tokens, as well as\ntime‑based one‑time passwords (TOTPs) have a defined lifetime. Out of band\nrequests must have a maximum lifetime of 10 minutes and for TOTP a\nmaximum lifetime of 30 seconds.\n2\n6.5.6\nVerify that any authentication factor (including physical devices) can be\nrevoked in case of theft or other loss.\n3\n6.5.7\nVerify that biometric authentication mechanisms are only used as secondary\nfactors together with either something you have or something you know.\n3\n6.5.8\nVerify that time‑based one‑time passwords (TOTPs) are checked based on a\ntime source from a trusted service and not from an untrusted or client\nprovided time.\n3\nV6.6 Out‑of‑Band authentication mechanisms\nThis usually involves the authentication server communicating with a physical device over a secure\nsecondary channel. For example, sending push notifications to mobile devices. This type of authen‑\ntication mechanism is considered “something you have”.\nUnsafe out‑of‑band authentication mechanisms such as e‑mail and VOIP are not permitted. PSTN\nand SMS authentication are currently considered to be “restricted”authentication mechanisms by\n49",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 43
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nNIST and should be deprecated in favor of Time based One‑time Passwords (TOTPs), a cryptographic\nmechanism, or similar. NIST SP 800‑63B § 5.1.3.3 recommends addressing the risks of device swap,\nSIM change, number porting, or other abnormal behavior, if telephone or SMS out‑of‑band authen‑\ntication absolutely has to be supported. While this ASVS section does not mandate this as a require‑\nment, not taking these precautions for a sensitive L2 app or an L3 app should be seen as a significant\nred flag.\nNote that NIST has also recently provided guidance which discourages the use of push notifications.\nWhile this ASVS section does not do so, it is important to be aware of the risks of “push bombing”.\n#\nDescription\nLevel\n6.6.1\nVerify that authentication mechanisms using the Public Switched Telephone\nNetwork (PSTN) to deliver One‑time Passwords (OTPs) via phone or SMS are\noffered only when the phone number has previously been validated,\nalternate stronger methods (such as Time based One‑time Passwords) are\nalso offered, and the service provides information on their security risks to\nusers. For L3 applications, phone and SMS must not be available as options.\n2\n6.6.2\nVerify that out‑of‑band authentication requests, codes, or tokens are bound\nto the original authentication request for which they were generated and are\nnot usable for a previous or subsequent one.\n2\n6.6.3\nVerify that a code based out‑of‑band authentication mechanism is protected\nagainst brute force attacks by using rate limiting. Consider also using a code\nwith at least 64 bits of entropy.\n2\n6.6.4\nVerify that, where push notifications are used for multi‑factor\nauthentication, rate limiting is used to prevent push bombing attacks.\nNumber matching may also mitigate this risk.\n3\nV6.7 Cryptographic authentication mechanism\nCryptographic authentication mechanisms include smart cards or FIDO keys, where the user has to\nplug in or pair the cryptographic device to the computer to complete authentication. The authenti‑\ncation server will send a challenge nonce to the cryptographic device or software, and the device or\nsoftware calculates a response based upon a securely stored cryptographic key. The requirements\nin this section provide implementation‑specific guidance for these mechanisms, with guidance on\ncryptographic algorithms being covered in the “Cryptography”chapter.\nWhere shared or secret keys are used for cryptographic authentication, these should be stored using\nthe same mechanisms as other system secrets, as documented in the “Secret Management”section\nin the “Configuration”chapter.\nThe requirements in this section mostly relate to § 5.1.7.2 of NIST’s Guidance.\n50",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 44
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n6.7.1\nVerify that the certificates used to verify cryptographic authentication\nassertions are stored in a way protects them from modification.\n3\n6.7.2\nVerify that the challenge nonce is at least 64 bits in length, and statistically\nunique or unique over the lifetime of the cryptographic device.\n3\nV6.8 Authentication with an Identity Provider\nIdentity Providers (IdPs) provide federated identity for users. Users will often have more than one\nidentity with multiple IdPs, such as an enterprise identity using Azure AD, Okta, Ping Identity, or\nGoogle, or consumer identity using Facebook, Twitter, Google, or WeChat, to name just a few com‑\nmon alternatives. This list is not an endorsement of these companies or services, but simply an\nencouragement for developers to consider the reality that many users have many established identi‑\nties. Organizations should consider integrating with existing user identities, as per the risk profile of\nthe IdP’s strength of identity proofing. For example, it is unlikely a government organization would\naccept a social media identity as a login for sensitive systems, as it is easy to create fake or throw‑\naway identities, whereas a mobile game company may well need to integrate with major social media\nplatforms to grow their active player base.\nSecure use of external identity providers requires careful configuration and verification to prevent\nidentity spoofing or forged assertions. This section provides requirements to address these risks.\n#\nDescription\nLevel\n6.8.1\nVerify that, if the application supports multiple identity providers (IdPs), the\nuser’s identity cannot be spoofed via another supported identity provider\n(eg. by using the same user identifier). The standard mitigation would be for\nthe application to register and identify the user using a combination of the\nIdP ID (serving as a namespace) and the user’s ID in the IdP.\n2\n6.8.2\nVerify that the presence and integrity of digital signatures on authentication\nassertions (for example on JWTs or SAML assertions) are always validated,\nrejecting any assertions that are unsigned or have invalid signatures.\n2\n6.8.3\nVerify that SAML assertions are uniquely processed and used only once\nwithin the validity period to prevent replay attacks.\n2\n51",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 45
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n6.8.4\nVerify that, if an application uses a separate Identity Provider (IdP) and\nexpects specific authentication strength, methods, or recentness for specific\nfunctions, the application verifies this using the information returned by the\nIdP. For example, if OIDC is used, this might be achieved by validating ID\nToken claims such as ‘acr’, ‘amr’, and ‘auth_time’(if present). If the IdP does\nnot provide this information, the application must have a documented\nfallback approach that assumes that the minimum strength authentication\nmechanism was used (for example, single‑factor authentication using\nusername and password).\n2\nReferences\nFor more information, see also:\n• NIST SP 800‑63 ‑ Digital Identity Guidelines\n• NIST SP 800‑63B ‑ Authentication and Lifecycle Management\n• NIST SP 800‑63 FAQ\n• OWASP Web Security Testing Guide: Testing for Authentication\n• OWASP Password Storage Cheat Sheet\n• OWASP Forgot Password Cheat Sheet\n• OWASP Choosing and Using Security Questions Cheat Sheet\n• CISA Guidance on “Number Matching”\n• Details on the FIDO Alliance\nV7 Session Management\nControl Objective\nSession management mechanisms allow applications to correlate user and device interactions over\ntime, even when using stateless communication protocols (such as HTTP). Modern applications may\nuse multiple session tokens with distinct characteristics and purposes. A secure session manage‑\nment system is one that prevents attackers from obtaining, utilizing, or otherwise abusing a victim’\ns session. Applications maintaining sessions must ensure that the following high‑level session man‑\nagement requirements are met:\n• Sessions are unique to each individual and cannot be guessed or shared.\n• Sessions are invalidated when no longer required and are timed out during periods of inactivity.\n52",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 46
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nMany of the requirements in this chapter relate to selected NIST SP 800‑63 Digital Identity Guidelines\ncontrols, focusing on common threats and commonly exploited authentication weaknesses.\nNote that requirements for specific implementation details of certain session management mecha‑\nnisms can be found elsewhere:\n• HTTP Cookies are a common mechanism for securing session tokens. Specific security require‑\nments for cookies can be found in the “Web Frontend Security”chapter.\n• Self‑contained tokens are frequently used as a way of maintaining sessions. Specific security\nrequirements can be found in the “Self‑contained Tokens”chapter.\nV7.1 Session Management Documentation\nThere is no single pattern that suits all applications. Therefore, it is not feasible to define universal\nboundaries and limits that suit all cases. A risk analysis with documented security decisions related\nto session handling must be conducted as a prerequisite to implementation and testing. This ensures\nthat the session management system is tailored to the specific requirements of the application.\nRegardless of whether a stateful or “stateless”session mechanism is chosen, the analysis must be\ncomplete and documented to demonstrate that the selected solution is capable of satisfying all rel‑\nevant security requirements. Interaction with any Single Sign‑on (SSO) mechanisms in use should\nalso be considered.\n#\nDescription\nLevel\n7.1.1\nVerify that the user’s session inactivity timeout and absolute maximum\nsession lifetime are documented, are appropriate in combination with other\ncontrols, and that the documentation includes justification for any\ndeviations from NIST SP 800‑63B re‑authentication requirements.\n2\n7.1.2\nVerify that the documentation defines how many concurrent (parallel)\nsessions are allowed for one account as well as the intended behaviors and\nactions to be taken when the maximum number of active sessions is reached.\n2\n7.1.3\nVerify that all systems that create and manage user sessions as part of a\nfederated identity management ecosystem (such as SSO systems) are\ndocumented along with controls to coordinate session lifetimes,\ntermination, and any other conditions that require re‑authentication.\n2\nV7.2 Fundamental Session Management Security\nThis section satisfies the essential requirements of secure sessions by verifying that session tokens\nare securely generated and validated.\n53",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 47
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n7.2.1\nVerify that the application performs all session token verification using a\ntrusted, backend service.\n1\n7.2.2\nVerify that the application uses either self‑contained or reference tokens that\nare dynamically generated for session management, i.e. not using static API\nsecrets and keys.\n1\n7.2.3\nVerify that if reference tokens are used to represent user sessions, they are\nunique and generated using a cryptographically secure pseudo‑random\nnumber generator (CSPRNG) and possess at least 128 bits of entropy.\n1\n7.2.4\nVerify that the application generates a new session token on user\nauthentication, including re‑authentication, and terminates the current\nsession token.\n1\nV7.3 Session Timeout\nSession timeout mechanisms serve to minimize the window of opportunity for session hijacking and\nother forms of session abuse. Timeouts must satisfy documented security decisions.\n#\nDescription\nLevel\n7.3.1\nVerify that there is an inactivity timeout such that re‑authentication is\nenforced according to risk analysis and documented security decisions.\n2\n7.3.2\nVerify that there is an absolute maximum session lifetime such that\nre‑authentication is enforced according to risk analysis and documented\nsecurity decisions.\n2\nV7.4 Session Termination\nSession termination may be handled either by the application itself or by the SSO provider if the SSO\nprovider is handling session management instead of the application. It may be necessary to decide\nwhether the SSO provider is in scope when considering the requirements in this section as some may\nbe controlled by the provider.\nSession termination should result in requiring re‑authentication and be effective across the applica‑\ntion, federated login (if present), and any relying parties.\nFor stateful session mechanisms, termination typically involves invalidating the session on the back‑\nend. In the case of self‑contained tokens, additional measures are required to revoke or block these\ntokens, as they may otherwise remain valid until expiration.\n54",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 48
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n7.4.1\nVerify that when session termination is triggered (such as logout or\nexpiration), the application disallows any further use of the session. For\nreference tokens or stateful sessions, this means invalidating the session\ndata at the application backend. Applications using self‑contained tokens\nwill need a solution such as maintaining a list of terminated tokens,\ndisallowing tokens produced before a per‑user date and time or rotating a\nper‑user signing key.\n1\n7.4.2\nVerify that the application terminates all active sessions when a user account\nis disabled or deleted (such as an employee leaving the company).\n1\n7.4.3\nVerify that the application gives the option to terminate all other active\nsessions after a successful change or removal of any authentication factor\n(including password change via reset or recovery and, if present, an MFA\nsettings update).\n2\n7.4.4\nVerify that all pages that require authentication have easy and visible access\nto logout functionality.\n2\n7.4.5\nVerify that application administrators are able to terminate active sessions\nfor an individual user or for all users.\n2\nV7.5 Defenses Against Session Abuse\nThis section provides requirements to mitigate the risk posed by active sessions that are either hi‑\njacked or abused through vectors that rely on the existence and capabilities of active user sessions.\nFor example, using malicious content execution to force an authenticated victim browser to perform\nan action using the victim’s session.\nNote that the level‑specific guidance in the “Authentication”chapter should be taken into account\nwhen considering requirements in this section.\n#\nDescription\nLevel\n7.5.1\nVerify that the application requires full re‑authentication before allowing\nmodifications to sensitive account attributes which may affect\nauthentication such as email address, phone number, MFA configuration, or\nother information used in account recovery.\n2\n7.5.2\nVerify that users are able to view and (having authenticated again with at\nleast one factor) terminate any or all currently active sessions.\n2\n55",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 49
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n7.5.3\nVerify that the application requires further authentication with at least one\nfactor or secondary verification before performing highly sensitive\ntransactions or operations.\n3\nV7.6 Federated Re‑authentication\nThis section relates to those writing Relying Party (RP) or Identity Provider (IdP) code. These re‑\nquirements are derived from the NIST SP 800‑63C for Federation & Assertions.\n#\nDescription\nLevel\n7.6.1\nVerify that session lifetime and termination between Relying Parties (RPs)\nand Identity Providers (IdPs) behave as documented, requiring\nre‑authentication as necessary such as when the maximum time between\nIdP authentication events is reached.\n2\n7.6.2\nVerify that creation of a session requires either the user’s consent or an\nexplicit action, preventing the creation of new application sessions without\nuser interaction.\n2\nReferences\nFor more information, see also:\n• OWASP Web Security Testing Guide: Session Management Testing\n• OWASP Session Management Cheat Sheet\nV8 Authorization\nControl Objective\nAuthorization ensures that access is granted only to permitted consumers (users, servers, and other\nclients). To enforce the Principle of Least Privilege (POLP), verified applications must meet the fol‑\nlowing high‑level requirements:\n• Document authorization rules, including decision‑making factors and environmental contexts.\n• Consumers should have access only to resources permitted by their defined entitlements.\n56",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 50
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nV8.1 Authorization Documentation\nComprehensive authorization documentation is essential to ensure that security decisions are con‑\nsistently applied, auditable, and aligned with organizational policies. This reduces the risk of unau‑\nthorized access by making security requirements clear and actionable for developers, administra‑\ntors, and testers.\n#\nDescription\nLevel\n8.1.1\nVerify that authorization documentation defines rules for restricting\nfunction‑level and data‑specific access based on consumer permissions and\nresource attributes.\n1\n8.1.2\nVerify that authorization documentation defines rules for field‑level access\nrestrictions (both read and write) based on consumer permissions and\nresource attributes. Note that these rules might depend on other attribute\nvalues of the relevant data object, such as state or status.\n2\n8.1.3\nVerify that the application’s documentation defines the environmental and\ncontextual attributes (including but not limited to, time of day, user location,\nIP address, or device) that are used in the application to make security\ndecisions, including those pertaining to authentication and authorization.\n3\n8.1.4\nVerify that authentication and authorization documentation defines how\nenvironmental and contextual factors are used in decision‑making, in\naddition to function‑level, data‑specific, and field‑level authorization. This\nshould include the attributes evaluated, thresholds for risk, and actions\ntaken (e.g., allow, challenge, deny, step‑up authentication).\n3\nV8.2 General Authorization Design\nImplementing granular authorization controls at the function, data, and field levels ensures that con‑\nsumers can access only what has been explicitly granted to them.\n#\nDescription\nLevel\n8.2.1\nVerify that the application ensures that function‑level access is restricted to\nconsumers with explicit permissions.\n1\n8.2.2\nVerify that the application ensures that data‑specific access is restricted to\nconsumers with explicit permissions to specific data items to mitigate\ninsecure direct object reference (IDOR) and broken object level\nauthorization (BOLA).\n1\n57",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 51
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n8.2.3\nVerify that the application ensures that field‑level access is restricted to\nconsumers with explicit permissions to specific fields to mitigate broken\nobject property level authorization (BOPLA).\n2\n8.2.4\nVerify that adaptive security controls based on a consumer’s environmental\nand contextual attributes (such as time of day, location, IP address, or device)\nare implemented for authentication and authorization decisions, as defined\nin the application’s documentation. These controls must be applied when\nthe consumer tries to start a new session and also during an existing session.\n3\nV8.3 Operation Level Authorization\nThe immediate application of authorization changes in the appropriate tier of an application’s archi‑\ntecture is crucial to preventing unauthorized actions, especially in dynamic environments.\n#\nDescription\nLevel\n8.3.1\nVerify that the application enforces authorization rules at a trusted service\nlayer and doesn’t rely on controls that an untrusted consumer could\nmanipulate, such as client‑side JavaScript.\n1\n8.3.2\nVerify that changes to values on which authorization decisions are made are\napplied immediately. Where changes cannot be applied immediately, (such\nas when relying on data in self‑contained tokens), there must be mitigating\ncontrols to alert when a consumer performs an action when they are no\nlonger authorized to do so and revert the change. Note that this alternative\nwould not mitigate information leakage.\n3\n8.3.3\nVerify that access to an object is based on the originating subject’s\n(e.g. consumer’s) permissions, not on the permissions of any intermediary\nor service acting on their behalf. For example, if a consumer calls a web\nservice using a self‑contained token for authentication, and the service then\nrequests data from a different service, the second service will use the\nconsumer’s token, rather than a machine‑to‑machine token from the first\nservice, to make permission decisions.\n3\nV8.4 Other Authorization Considerations\nAdditional considerations for authorization, particularly for administrative interfaces and multi‑\ntenant environments, help prevent unauthorized access.\n58",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 52
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n8.4.1\nVerify that multi‑tenant applications use cross‑tenant controls to ensure\nconsumer operations will never affect tenants with which they do not have\npermissions to interact.\n2\n8.4.2\nVerify that access to administrative interfaces incorporates multiple layers of\nsecurity, including continuous consumer identity verification, device\nsecurity posture assessment, and contextual risk analysis, ensuring that\nnetwork location or trusted endpoints are not the sole factors for\nauthorization even though they may reduce the likelihood of unauthorized\naccess.\n3\nReferences\nFor more information, see also:\n• OWASP Web Security Testing Guide: Authorization\n• OWASP Authorization Cheat Sheet\nV9 Self‑contained Tokens\nControl Objective\nThe concept of a self‑contained token is mentioned in the original RFC 6749 OAuth 2.0 from 2012.\nIt refers to a token containing data or claims on which a receiving service will rely to make security\ndecisions. This should be differentiated from a simple token containing only an identifier, which a\nreceiving service uses to look up data locally. The most common examples of self‑contained tokens\nare JSON Web Tokens (JWTs) and SAML assertions.\nThe use of self‑contained tokens has become very widespread, even outside of OAuth and OIDC. At\nthe same time, the security of this mechanism relies on the ability to validate the integrity of the\ntoken and to ensure that the token is valid for a particular context. There are many pitfalls with this\nprocess, and this chapter provides specific details of the mechanisms that applications should have\nin place to prevent them.\nV9.1 Token source and integrity\nThis section includes requirements to ensure that the token has been produced by a trusted party\nand has not been tampered with.\n59",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 53
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n9.1.1\nVerify that self‑contained tokens are validated using their digital signature or\nMAC to protect against tampering before accepting the token’s contents.\n1\n9.1.2\nVerify that only algorithms on an allowlist can be used to create and verify\nself‑contained tokens, for a given context. The allowlist must include the\npermitted algorithms, ideally only either symmetric or asymmetric\nalgorithms, and must not include the ‘None’algorithm. If both symmetric\nand asymmetric must be supported, additional controls will be needed to\nprevent key confusion.\n1\n9.1.3\nVerify that key material that is used to validate self‑contained tokens is from\ntrusted pre‑configured sources for the token issuer, preventing attackers\nfrom specifying untrusted sources and keys. For JWTs and other JWS\nstructures, headers such as ‘jku’, ‘x5u’, and ‘jwk’must be validated against an\nallowlist of trusted sources.\n1\nV9.2 Token content\nBefore making security decisions based on the content of a self‑contained token, it is necessary to\nvalidate that the token has been presented within its validity period and that it is intended for use\nby the receiving service and for the purpose for which it was presented. This helps avoid insecure\ncross‑usage between different services or with different token types from the same issuer.\nSpecific requirements for OAuth and OIDC are covered in the dedicated chapter.\n#\nDescription\nLevel\n9.2.1\nVerify that, if a validity time span is present in the token data, the token and\nits content are accepted only if the verification time is within this validity\ntime span. For example, for JWTs, the claims ‘nbf’and ‘exp’must be verified.\n1\n9.2.2\nVerify that the service receiving a token validates the token to be the correct\ntype and is meant for the intended purpose before accepting the token’s\ncontents. For example, only access tokens can be accepted for authorization\ndecisions and only ID Tokens can be used for proving user authentication.\n2\n9.2.3\nVerify that the service only accepts tokens which are intended for use with\nthat service (audience). For JWTs, this can be achieved by validating the ‘aud’\nclaim against an allowlist defined in the service.\n2\n60",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 54
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n9.2.4\nVerify that, if a token issuer uses the same private key for issuing tokens to\ndifferent audiences, the issued tokens contain an audience restriction that\nuniquely identifies the intended audiences. This will prevent a token from\nbeing reused with an unintended audience. If the audience identifier is\ndynamically provisioned, the token issuer must validate these audiences in\norder to make sure that they do not result in audience impersonation.\n2\nReferences\nFor more information, see also:\n• OWASP JSON Web Token Cheat Sheet for Java Cheat Sheet (but has useful general guidance)\nV10 OAuth and OIDC\nControl Objective\nOAuth2 (referred to as OAuth in this chapter) is an industry‑standard framework for delegated autho‑\nrization. For example, using OAuth, a client application can obtain access to APIs (server resources)\non a user’s behalf, provided the user has authorized the client application to do so.\nBy itself, OAuth is not designed for user authentication. The OpenID Connect (OIDC) framework\nextends OAuth by adding a user identity layer on top of OAuth. OIDC provides support for features\nincluding standardized user information, Single Sign‑On (SSO), and session management. As OIDC\nis an extension of OAuth, the OAuth requirements in this chapter also apply to OIDC.\nThe following roles are defined in OAuth:\n• The OAuth client is the application that attempts to obtain access to server resources (e.g., by\ncalling an API using the issued access token). The OAuth client is often a server‑side application.\n– A confidential client is a client capable of maintaining the confidentiality of the credentials\nit uses to authenticate itself with the authorization server.\n– A public client is not capable of maintaining the confidentiality of credentials for authen‑\nticating with the authorization server. Therefore, instead of authenticating itself (e.g.,\nusing ‘client_id’and ‘client_secret’parameters), it only identifies itself (using a ‘client_id’\nparameter).\n• The OAuth resource server (RS) is the server API exposing resources to OAuth clients.\n• The OAuth authorization server (AS) is a server application that issues access tokens to OAuth\nclients. These access tokens allow OAuth clients to access RS resources, either on behalf of an\n61",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 55
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nend‑user or on the OAuth client’s own behalf. The AS is often a separate application, but (if\nappropriate) it may be integrated into a suitable RS.\n• The resource owner (RO) is the end‑user who authorizes OAuth clients to obtain limited access\nto resources hosted on the resource server on their behalf. The resource owner consents to\nthis delegated authorization by interacting with the authorization server.\nThe following roles are defined in OIDC:\n• The relying party (RP) is the client application requesting end‑user authentication through the\nOpenID Provider. It assumes the role of an OAuth client.\n• The OpenID Provider (OP) is an OAuth AS that is capable of authenticating the end‑user and\nprovides OIDC claims to an RP. The OP may be the identity provider (IdP), but in federated\nscenarios, the OP and the identity provider (where the end‑user authenticates) may be different\nserver applications.\nOAuth and OIDC were initially designed for third‑party applications. Today, they are often used by\nfirst‑party applications as well. However, when used in first‑party scenarios, such as authentication\nand session management, the protocol adds some complexity, which may introduce new security\nchallenges.\nOAuth and OIDC can be used for many types of applications, but the focus for ASVS and the require‑\nments in this chapter is on web applications and APIs.\nSince OAuth and OIDC can be considered logic on top of web technologies, general requirements\nfrom other chapters always apply, and this chapter cannot be taken out of context.\nThis chapter addresses best current practices for OAuth2 and OIDC aligned with specifications found\nat https://oauth.net/2/ and https://openid.net/developers/specs/. Even if RFCs are considered\nmature, they are updated frequently. Thus, it is important to align with the latest versions when\napplying the requirements in this chapter. See the references section for more details.\nGiven the complexity of the area, it is vitally important for a secure OAuth or OIDC solution to use\nwell‑known industry‑standard authorization servers and apply the recommended security configu‑\nration.\nTerminology used in this chapter aligns with OAuth RFCs and OIDC specifications, but note that OIDC\nterminology is only used for OIDC‑specific requirements; otherwise, OAuth terminology is used.\nIn the context of OAuth and OIDC, the term “token”in this chapter refers to:\n• Access tokens, which shall only be consumed by the RS and can either be reference tokens that\nare validated using introspection or self‑contained tokens that are validated using some key\nmaterial.\n• Refresh tokens, which shall only be consumed by the authorization server that issued the token.\n• OIDC ID Tokens, which shall only be consumed by the client that triggered the authorization\nflow.\n62",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 56
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nThe risk levels for some of the requirements in this chapter depend on whether the client is a confi‑\ndential client or regarded as a public client. Since using strong client authentication mitigates many\nattack vectors, a few requirements might be relaxed when using a confidential client for L1 applica‑\ntions.\nV10.1 Generic OAuth and OIDC Security\nThis section covers generic architectural requirements that apply to all applications using OAuth or\nOIDC.\n#\nDescription\nLevel\n10.1.1\nVerify that tokens are only sent to components that strictly need them. For\nexample, when using a backend‑for‑frontend pattern for browser‑based\nJavaScript applications, access and refresh tokens shall only be accessible for\nthe backend.\n2\n10.1.2\nVerify that the client only accepts values from the authorization server (such\nas the authorization code or ID Token) if these values result from an\nauthorization flow that was initiated by the same user agent session and\ntransaction. This requires that client‑generated secrets, such as the proof\nkey for code exchange (PKCE) ‘code_verifier’, ‘state’or OIDC ‘nonce’, are not\nguessable, are specific to the transaction, and are securely bound to both the\nclient and the user agent session in which the transaction was started.\n2\nV10.2 OAuth Client\nThese requirements detail the responsibilities for OAuth client applications. The client can be, for\nexample, a web server backend (often acting as a Backend For Frontend, BFF), a backend service\nintegration, or a frontend Single Page Application (SPA, aka browser‑based application).\nIn general, backend clients are regarded as confidential clients and frontend clients are regarded\nas public clients. However, native applications running on the end‑user device can be regarded as\nconfidential when using OAuth dynamic client registration.\n#\nDescription\nLevel\n10.2.1\nVerify that, if the code flow is used, the OAuth client has protection against\nbrowser‑based request forgery attacks, commonly known as cross‑site\nrequest forgery (CSRF), which trigger token requests, either by using proof\nkey for code exchange (PKCE) functionality or checking the ‘state’parameter\nthat was sent in the authorization request.\n2\n63",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 57
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n10.2.2\nVerify that, if the OAuth client can interact with more than one authorization\nserver, it has a defense against mix‑up attacks. For example, it could require\nthat the authorization server return the ‘iss’parameter value and validate it\nin the authorization response and the token response.\n2\n10.2.3\nVerify that the OAuth client only requests the required scopes (or other\nauthorization parameters) in requests to the authorization server.\n3\nV10.3 OAuth Resource Server\nIn the context of ASVS and this chapter, the resource server is an API. To provide secure access, the\nresource server must:\n• Validate the access token, according to the token format and relevant protocol specifications,\ne.g., JWT‑validation or OAuth token introspection.\n• If valid, enforce authorization decisions based on the information from the access token and\npermissions which have been granted. For example, the resource server needs to verify that\nthe client (acting on behalf of RO) is authorized to access the requested resource.\nTherefore, the requirements listed here are OAuth or OIDC specific and should be performed after\ntoken validation and before performing authorization based on information from the token.\n#\nDescription\nLevel\n10.3.1\nVerify that the resource server only accepts access tokens that are intended\nfor use with that service (audience). The audience may be included in a\nstructured access token (such as the ‘aud’claim in JWT), or it can be checked\nusing the token introspection endpoint.\n2\n10.3.2\nVerify that the resource server enforces authorization decisions based on\nclaims from the access token that define delegated authorization. If claims\nsuch as ‘sub’, ‘scope’, and ‘authorization_details’are present, they must be\npart of the decision.\n2\n10.3.3\nVerify that if an access control decision requires identifying a unique user\nfrom an access token (JWT or related token introspection response), the\nresource server identifies the user from claims that cannot be reassigned to\nother users. Typically, it means using a combination of ‘iss’and ‘sub’claims.\n2\n64",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 58
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n10.3.4\nVerify that, if the resource server requires specific authentication strength,\nmethods, or recentness, it verifies that the presented access token satisfies\nthese constraints. For example, if present, using the OIDC ‘acr’, ‘amr’and\n‘auth_time’claims respectively.\n2\n10.3.5\nVerify that the resource server prevents the use of stolen access tokens or\nreplay of access tokens (from unauthorized parties) by requiring\nsender‑constrained access tokens, either Mutual TLS for OAuth 2 or OAuth 2\nDemonstration of Proof of Possession (DPoP).\n3\nV10.4 OAuth Authorization Server\nThese requirements detail the responsibilities for OAuth authorization servers, including OpenID\nProviders.\nFor client authentication, the ‘self_signed_tls_client_auth’method is allowed with the prerequisites\nrequired by section 2.2 of RFC 8705.\n#\nDescription\nLevel\n10.4.1\nVerify that the authorization server validates redirect URIs based on a\nclient‑specific allowlist of pre‑registered URIs using exact string comparison.\n1\n10.4.2\nVerify that, if the authorization server returns the authorization code in the\nauthorization response, it can be used only once for a token request. For the\nsecond valid request with an authorization code that has already been used\nto issue an access token, the authorization server must reject a token request\nand revoke any issued tokens related to the authorization code.\n1\n10.4.3\nVerify that the authorization code is short‑lived. The maximum lifetime can\nbe up to 10 minutes for L1 and L2 applications and up to 1 minute for L3\napplications.\n1\n10.4.4\nVerify that for a given client, the authorization server only allows the usage\nof grants that this client needs to use. Note that the grants ‘token’(Implicit\nflow) and ‘password’(Resource Owner Password Credentials flow) must no\nlonger be used.\n1\n65",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 59
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n10.4.5\nVerify that the authorization server mitigates refresh token replay attacks for\npublic clients, preferably using sender‑constrained refresh tokens, i.e.,\nDemonstrating Proof of Possession (DPoP) or Certificate‑Bound Access\nTokens using mutual TLS (mTLS). For L1 and L2 applications, refresh token\nrotation may be used. If refresh token rotation is used, the authorization\nserver must invalidate the refresh token after usage, and revoke all refresh\ntokens for that authorization if an already used and invalidated refresh token\nis provided.\n1\n10.4.6\nVerify that, if the code grant is used, the authorization server mitigates\nauthorization code interception attacks by requiring proof key for code\nexchange (PKCE). For authorization requests, the authorization server must\nrequire a valid ‘code_challenge’value and must not accept a\n‘code_challenge_method’value of ‘plain’. For a token request, it must require\nvalidation of the ‘code_verifier’parameter.\n2\n10.4.7\nVerify that if the authorization server supports unauthenticated dynamic\nclient registration, it mitigates the risk of malicious client applications. It\nmust validate client metadata such as any registered URIs, ensure the user’s\nconsent, and warn the user before processing an authorization request with\nan untrusted client application.\n2\n10.4.8\nVerify that refresh tokens have an absolute expiration, including if sliding\nrefresh token expiration is applied.\n2\n10.4.9\nVerify that refresh tokens and reference access tokens can be revoked by an\nauthorized user using the authorization server user interface, to mitigate the\nrisk of malicious clients or stolen tokens.\n2\n10.4.10\nVerify that confidential client is authenticated for client‑to‑authorized server\nbackchannel requests such as token requests, pushed authorization requests\n(PAR), and token revocation requests.\n2\n10.4.11\nVerify that the authorization server configuration only assigns the required\nscopes to the OAuth client.\n2\n10.4.12\nVerify that for a given client, the authorization server only allows the\n‘response_mode’value that this client needs to use. For example, by having\nthe authorization server validate this value against the expected values or by\nusing pushed authorization request (PAR) or JWT‑secured Authorization\nRequest (JAR).\n3\n10.4.13\nVerify that grant type ‘code’is always used together with pushed\nauthorization requests (PAR).\n3\n66",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 60
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n10.4.14\nVerify that the authorization server issues only sender‑constrained\n(Proof‑of‑Possession) access tokens, either with certificate‑bound access\ntokens using mutual TLS (mTLS) or DPoP‑bound access tokens\n(Demonstration of Proof of Possession).\n3\n10.4.15\nVerify that, for a server‑side client (which is not executed on the end‑user\ndevice), the authorization server ensures that the ‘authorization_details’\nparameter value is from the client backend and that the user has not\ntampered with it. For example, by requiring the usage of pushed\nauthorization request (PAR) or JWT‑secured Authorization Request (JAR).\n3\n10.4.16\nVerify that the client is confidential and the authorization server requires the\nuse of strong client authentication methods (based on public‑key\ncryptography and resistant to replay attacks), such as mutual TLS (\n‘tls_client_auth’, ‘self_signed_tls_client_auth’) or private key JWT (\n‘private_key_jwt’).\n3\nV10.5 OIDC Client\nAs the OIDC relying party acts as an OAuth client, the requirements from the section “OAuth Client”\napply as well.\nNote that the “Authentication with an Identity Provider”section in the “Authentication”chapter also\ncontains relevant general requirements.\n#\nDescription\nLevel\n10.5.1\nVerify that the client (as the relying party) mitigates ID Token replay attacks.\nFor example, by ensuring that the ‘nonce’claim in the ID Token matches the\n‘nonce’value sent in the authentication request to the OpenID Provider (in\nOAuth2 refereed to as the authorization request sent to the authorization\nserver).\n2\n10.5.2\nVerify that the client uniquely identifies the user from ID Token claims,\nusually the ‘sub’claim, which cannot be reassigned to other users (for the\nscope of an identity provider).\n2\n10.5.3\nVerify that the client rejects attempts by a malicious authorization server to\nimpersonate another authorization server through authorization server\nmetadata. The client must reject authorization server metadata if the issuer\nURL in the authorization server metadata does not exactly match the\npre‑configured issuer URL expected by the client.\n2\n67",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 61
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n10.5.4\nVerify that the client validates that the ID Token is intended to be used for\nthat client (audience) by checking that the ‘aud’claim from the token is equal\nto the ‘client_id’value for the client.\n2\n10.5.5\nVerify that, when using OIDC back‑channel logout, the relying party\nmitigates denial of service through forced logout and cross‑JWT confusion in\nthe logout flow. The client must verify that the logout token is correctly typed\nwith a value of ‘logout+jwt’, contains the ‘event’claim with the correct\nmember name, and does not contain a ‘nonce’claim. Note that it is also\nrecommended to have a short expiration (e.g., 2 minutes).\n2\nV10.6 OpenID Provider\nAs OpenID Providers act as OAuth authorization servers, the requirements from the section “OAuth\nAuthorization Server”apply as well.\nNote that if using the ID Token flow (not the code flow), no access tokens are issued, and many of the\nrequirements for OAuth AS are not applicable.\n#\nDescription\nLevel\n10.6.1\nVerify that the OpenID Provider only allows values ‘code’, ‘ciba’, ‘id_token’,\nor ‘id_token code’for response mode. Note that ‘code’is preferred over\n‘id_token code’(the OIDC Hybrid flow), and ‘token’(any Implicit flow) must\nnot be used.\n2\n10.6.2\nVerify that the OpenID Provider mitigates denial of service through forced\nlogout. By obtaining explicit confirmation from the end‑user or, if present,\nvalidating parameters in the logout request (initiated by the relying party),\nsuch as the ‘id_token_hint’.\n2\nV10.7 Consent Management\nThese requirements cover the verification of the user’s consent by the authorization server. With‑\nout proper user consent verification, a malicious actor may obtain permissions on the user’s behalf\nthrough spoofing or social‑engineering.\n68",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 62
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n10.7.1\nVerify that the authorization server ensures that the user consents to each\nauthorization request. If the identity of the client cannot be assured, the\nauthorization server must always explicitly prompt the user for consent.\n2\n10.7.2\nVerify that when the authorization server prompts for user consent, it\npresents sufficient and clear information about what is being consented to.\nWhen applicable, this should include the nature of the requested\nauthorizations (typically based on scope, resource server, Rich Authorization\nRequests (RAR) authorization details), the identity of the authorized\napplication, and the lifetime of these authorizations.\n2\n10.7.3\nVerify that the user can review, modify, and revoke consents which the user\nhas granted through the authorization server.\n2\nReferences\nFor more information on OAuth, please see:\n• oauth.net\n• OWASP OAuth 2.0 Protocol Cheat Sheet\nFor OAuth‑related requirements in ASVS following published and in draft status RFC‑s are used:\n• RFC6749 The OAuth 2.0 Authorization Framework\n• RFC6750 The OAuth 2.0 Authorization Framework: Bearer Token Usage\n• RFC6819 OAuth 2.0 Threat Model and Security Considerations\n• RFC7636 Proof Key for Code Exchange by OAuth Public Clients\n• RFC7591 OAuth 2.0 Dynamic Client Registration Protocol\n• RFC8628 OAuth 2.0 Device Authorization Grant\n• RFC8707 Resource Indicators for OAuth 2.0\n• RFC9068 JSON Web Token (JWT) Profile for OAuth 2.0 Access Tokens\n• RFC9126 OAuth 2.0 Pushed Authorization Requests\n• RFC9207 OAuth 2.0 Authorization Server Issuer Identification\n• RFC9396 OAuth 2.0 Rich Authorization Requests\n• RFC9449 OAuth 2.0 Demonstrating Proof of Possession (DPoP)\n• RFC9700 Best Current Practice for OAuth 2.0 Security\n• draft OAuth 2.0 for Browser‑Based Applications\n• draft The OAuth 2.1 Authorization Framework\nFor more information on OpenID Connect, please see:\n• OpenID Connect Core 1.0\n69",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 63
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• FAPI 2.0 Security Profile\nV11 Cryptography\nControl Objective\nThe objective of this chapter is to define best practices for the general use of cryptography, as well as\nto instill a fundamental understanding of cryptographic principles and inspire a shift toward more\nresilient and modern approaches. It encourages the following:\n• Implementing robust cryptographic systems that fail securely, adapt to evolving threats, and\nare future‑proof.\n• Utilizing cryptographic mechanisms that are both secure and aligned with industry best prac‑\ntices.\n• Maintaining a secure cryptographic key management system with appropriate access controls\nand auditing.\n• Regularly evaluating the cryptographic landscape to assess new risks and adapt algorithms ac‑\ncordingly.\n• Discovering and managing cryptographic use cases throughout the application’s lifecycle to\nensure that all cryptographic assets are accounted for and secured.\nIn addition to outlining general principles and best practices, this document also provides more in‑\ndepth technical information about the requirements in Appendix C ‑ Cryptography Standards. This\nincludes algorithms and modes that are considered “approved”for the purposes of the requirements\nin this chapter.\nRequirements that use cryptography to solve a separate problem, such as secrets management or\ncommunications security, will be in different parts of the standard.\nV11.1 Cryptographic Inventory and Documentation\nApplications need to be designed with strong cryptographic architecture to protect data assets ac‑\ncording to their classification. Encrypting everything is wasteful; not encrypting anything is legally\nnegligent. A balance must be struck, usually during architectural or high‑level design, design sprints,\nor architectural spikes. Designing cryptography “on the fly”or retrofitting it will inevitably cost much\nmore to implement securely than simply building it in from the start.\nIt is important to ensure that all cryptographic assets are regularly discovered, inventoried, and as‑\nsessed. Please see the appendix for more information on how this can be done.\nThe need to future‑proof cryptographic systems against the eventual rise of quantum computing\nis also critical. Post‑Quantum Cryptography (PQC) refers to cryptographic algorithms designed to\n70",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 64
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nremain secure against attacks by quantum computers, which are expected to break widely used al‑\ngorithms such as RSA and elliptic curve cryptography (ECC).\nPlease see the appendix for current guidance on vetted PQC primitives and standards.\n#\nDescription\nLevel\n11.1.1\nVerify that there is a documented policy for management of cryptographic\nkeys and a cryptographic key lifecycle that follows a key management\nstandard such as NIST SP 800‑57. This should include ensuring that keys are\nnot overshared (for example, with more than two entities for shared secrets\nand more than one entity for private keys).\n2\n11.1.2\nVerify that a cryptographic inventory is performed, maintained, regularly\nupdated, and includes all cryptographic keys, algorithms, and certificates\nused by the application. It must also document where keys can and cannot\nbe used in the system, and the types of data that can and cannot be protected\nusing the keys.\n2\n11.1.3\nVerify that cryptographic discovery mechanisms are employed to identify all\ninstances of cryptography in the system, including encryption, hashing, and\nsigning operations.\n3\n11.1.4\nVerify that a cryptographic inventory is maintained. This must include a\ndocumented plan that outlines the migration path to new cryptographic\nstandards, such as post‑quantum cryptography, in order to react to future\nthreats.\n3\nV11.2 Secure Cryptography Implementation\nThis section defines the requirements for the selection, implementation, and ongoing management\nof core cryptographic algorithms for an application. The objective is to ensure that only robust,\nindustry‑accepted cryptographic primitives are deployed, in alignment with current standards (e.g.,\nNIST, ISO/IEC) and best practices. Organizations must ensure that each cryptographic component\nis selected based on peer‑reviewed evidence and practical security testing.\n#\nDescription\nLevel\n11.2.1\nVerify that industry‑validated implementations (including libraries and\nhardware‑accelerated implementations) are used for cryptographic\noperations.\n2\n71",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 65
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n11.2.2\nVerify that the application is designed with crypto agility such that random\nnumber, authenticated encryption, MAC, or hashing algorithms, key\nlengths, rounds, ciphers and modes can be reconfigured, upgraded, or\nswapped at any time, to protect against cryptographic breaks. Similarly, it\nmust also be possible to replace keys and passwords and re‑encrypt data.\nThis will allow for seamless upgrades to post‑quantum cryptography (PQC),\nonce high‑assurance implementations of approved PQC schemes or\nstandards are widely available.\n2\n11.2.3\nVerify that all cryptographic primitives utilize a minimum of 128‑bits of\nsecurity based on the algorithm, key size, and configuration. For example, a\n256‑bit ECC key provides roughly 128 bits of security where RSA requires a\n3072‑bit key to achieve 128 bits of security.\n2\n11.2.4\nVerify that all cryptographic operations are constant‑time, with no\n‘short‑circuit’operations in comparisons, calculations, or returns, to avoid\nleaking information.\n3\n11.2.5\nVerify that all cryptographic modules fail securely, and errors are handled in\na way that does not enable vulnerabilities, such as Padding Oracle attacks.\n3\nV11.3 Encryption Algorithms\nAuthenticated encryption algorithms built on AES and CHACHA20 form the backbone of modern\ncryptographic practice.\n#\nDescription\nLevel\n11.3.1\nVerify that insecure block modes (e.g., ECB) and weak padding schemes\n(e.g., PKCS#1 v1.5) are not used.\n1\n11.3.2\nVerify that only approved ciphers and modes such as AES with GCM are used.\n1\n11.3.3\nVerify that encrypted data is protected against unauthorized modification\npreferably by using an approved authenticated encryption method or by\ncombining an approved encryption method with an approved MAC\nalgorithm.\n2\n11.3.4\nVerify that nonces, initialization vectors, and other single‑use numbers are\nnot used for more than one encryption key and data‑element pair. The\nmethod of generation must be appropriate for the algorithm being used.\n3\n72",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 66
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n11.3.5\nVerify that any combination of an encryption algorithm and a MAC\nalgorithm is operating in encrypt‑then‑MAC mode.\n3\nV11.4 Hashing and Hash‑based Functions\nCryptographic hashes are used in a wide variety of cryptographic protocols, such as digital signatures,\nHMAC, key derivation functions (KDF), random bit generation, and password storage. The security\nof the cryptographic system is only as strong as the underlying hash functions used. This section\noutlines the requirements for using secure hash functions in cryptographic operations.\nFor password storage, as well as the cryptography appendix, the OWASP Password Storage Cheat\nSheet will also provide useful context and guidance.\n#\nDescription\nLevel\n11.4.1\nVerify that only approved hash functions are used for general cryptographic\nuse cases, including digital signatures, HMAC, KDF, and random bit\ngeneration. Disallowed hash functions, such as MD5, must not be used for\nany cryptographic purpose.\n1\n11.4.2\nVerify that passwords are stored using an approved, computationally\nintensive, key derivation function (also known as a “password hashing\nfunction”), with parameter settings configured based on current guidance.\nThe settings should balance security and performance to make brute‑force\nattacks sufficiently challenging for the required level of security.\n2\n11.4.3\nVerify that hash functions used in digital signatures, as part of data\nauthentication or data integrity are collision resistant and have appropriate\nbit‑lengths. If collision resistance is required, the output length must be at\nleast 256 bits. If only resistance to second pre‑image attacks is required, the\noutput length must be at least 128 bits.\n2\n11.4.4\nVerify that the application uses approved key derivation functions with key\nstretching parameters when deriving secret keys from passwords. The\nparameters in use must balance security and performance to prevent\nbrute‑force attacks from compromising the resulting cryptographic key.\n2\nV11.5 Random Values\nCryptographically secure Pseudo‑random Number Generation (CSPRNG) is incredibly difficult to get\nright. Generally, good sources of entropy within a system will be quickly depleted if over‑used, but\n73",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 67
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nsources with less randomness can lead to predictable keys and secrets.\n#\nDescription\nLevel\n11.5.1\nVerify that all random numbers and strings which are intended to be\nnon‑guessable must be generated using a cryptographically secure\npseudo‑random number generator (CSPRNG) and have at least 128 bits of\nentropy. Note that UUIDs do not respect this condition.\n2\n11.5.2\nVerify that the random number generation mechanism in use is designed to\nwork securely, even under heavy demand.\n3\nV11.6 Public Key Cryptography\nPublic Key Cryptography will be used where it is not possible or not desirable to share a secret key\nbetween multiple parties.\nAs part of this, there exists a need for approved key exchange mechanisms, such as Diffie‑Hellman\nand Elliptic Curve Diffie‑Hellman (ECDH) to ensure that the cryptosystem remains secure against\nmodern threats. The “Secure Communication”chapter provides requirements for TLS so the require‑\nments in this section are intended for situations where Public Key Cryptography is being used in use\ncases other than TLS.\n#\nDescription\nLevel\n11.6.1\nVerify that only approved cryptographic algorithms and modes of operation\nare used for key generation and seeding, and digital signature generation\nand verification. Key generation algorithms must not generate insecure keys\nvulnerable to known attacks, for example, RSA keys which are vulnerable to\nFermat factorization.\n2\n11.6.2\nVerify that approved cryptographic algorithms are used for key exchange\n(such as Diffie‑Hellman) with a focus on ensuring that key exchange\nmechanisms use secure parameters. This will prevent attacks on the key\nestablishment process which could lead to adversary‑in‑the‑middle attacks\nor cryptographic breaks.\n3\nV11.7 In‑Use Data Cryptography\nProtecting data while it is being processed is paramount. Techniques such as full memory encryp‑\ntion, encryption of data in transit, and ensuring data is encrypted as quickly as possible after use is\nrecommended.\n74",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 68
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n11.7.1\nVerify that full memory encryption is in use that protects sensitive data\nwhile it is in use, preventing access by unauthorized users or processes.\n3\n11.7.2\nVerify that data minimization ensures the minimal amount of data is\nexposed during processing, and ensure that data is encrypted immediately\nafter use or as soon as feasible.\n3\nReferences\nFor more information, see also:\n• OWASP Web Security Testing Guide: Testing for Weak Cryptography\n• OWASP Cryptographic Storage Cheat Sheet\n• FIPS 140‑3\n• NIST SP 800‑57\nV12 Secure Communication\nControl Objective\nThis chapter includes requirements related to the specific mechanisms that should be in place to\nprotect data in transit, both between an end‑user client and a backend service, as well as between\ninternal and backend services.\nThe general concepts promoted by this chapter include:\n• Ensuring that communications are encrypted externally, and ideally internally as well.\n• Configuring encryption mechanisms using the latest guidance, including preferred algorithms\nand ciphers.\n• Ensuring that communications are not being intercepted by unauthorized parties through the\nuse of signed certificates.\nIn addition to outlining general principles and best practices, the ASVS also provides more in‑depth\ntechnical information about cryptographic strength in Appendix C ‑ Cryptography Standards.\nV12.1 General TLS Security Guidance\nThis section provides initial guidance on how to secure TLS communications. Up‑to‑date tools should\nbe used to review TLS configuration on an ongoing basis.\n75",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 69
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nWhile the use of wildcard TLS certificates is not inherently insecure, a compromise of a certificate\nthat is deployed across all owned environments (e.g., production, staging, development, and test)\nmay lead to a compromise of the security posture of the applications using it. Proper protection,\nmanagement, and the use of separate TLS certificates in different environments should be employed\nif possible.\n#\nDescription\nLevel\n12.1.1\nVerify that only the latest recommended versions of the TLS protocol are\nenabled, such as TLS 1.2 and TLS 1.3. The latest version of the TLS protocol\nmust be the preferred option.\n1\n12.1.2\nVerify that only recommended cipher suites are enabled, with the strongest\ncipher suites set as preferred. L3 applications must only support cipher\nsuites which provide forward secrecy.\n2\n12.1.3\nVerify that the application validates that mTLS client certificates are trusted\nbefore using the certificate identity for authentication or authorization.\n2\n12.1.4\nVerify that proper certification revocation, such as Online Certificate Status\nProtocol (OCSP) Stapling, is enabled and configured.\n3\n12.1.5\nVerify that Encrypted Client Hello (ECH) is enabled in the application’s TLS\nsettings to prevent exposure of sensitive metadata, such as the Server Name\nIndication (SNI), during TLS handshake processes.\n3\nV12.2 HTTPS Communication with External Facing Services\nEnsure all HTTP traffic to external‑facing services which the application exposes is sent encrypted,\nwith publicly trusted certificates.\n#\nDescription\nLevel\n12.2.1\nVerify that TLS is used for all connectivity between a client and external\nfacing, HTTP‑based services, and does not fall back to insecure or\nunencrypted communications.\n1\n12.2.2\nVerify that external facing services use publicly trusted TLS certificates.\n1\nV12.3 General Service to Service Communication Security\nServer communications (both internal and external) involve more than just HTTP. Connections to\nand from other systems must also be secure, ideally using TLS.\n76",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 70
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n12.3.1\nVerify that an encrypted protocol such as TLS is used for all inbound and\noutbound connections to and from the application, including monitoring\nsystems, management tools, remote access and SSH, middleware, databases,\nmainframes, partner systems, or external APIs. The server must not fall\nback to insecure or unencrypted protocols.\n2\n12.3.2\nVerify that TLS clients validate certificates received before communicating\nwith a TLS server.\n2\n12.3.3\nVerify that TLS or another appropriate transport encryption mechanism\nused for all connectivity between internal, HTTP‑based services within the\napplication, and does not fall back to insecure or unencrypted\ncommunications.\n2\n12.3.4\nVerify that TLS connections between internal services use trusted\ncertificates. Where internally generated or self‑signed certificates are used,\nthe consuming service must be configured to only trust specific internal CAs\nand specific self‑signed certificates.\n2\n12.3.5\nVerify that services communicating internally within a system (intra‑service\ncommunications) use strong authentication to ensure that each endpoint is\nverified. Strong authentication methods, such as TLS client authentication,\nmust be employed to ensure identity, using public‑key infrastructure and\nmechanisms that are resistant to replay attacks. For microservice\narchitectures, consider using a service mesh to simplify certificate\nmanagement and enhance security.\n3\nReferences\nFor more information, see also:\n• OWASP ‑ Transport Layer Security Cheat Sheet\n• Mozilla’s Server Side TLS configuration guide\n• Mozilla’s tool to generate known good TLS configurations.\n• O‑Saft ‑ OWASP Project to validate TLS configuration\nV13 Configuration\nControl Objective\nThe application’s default configuration must be secure for use on the Internet.\n77",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 71
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nThis chapter provides guidance on the various configurations necessary to achieve this, including\nthose applied during development, build, and deployment.\nTopics covered include preventing data leakage, securely managing communication between com‑\nponents, and protecting secrets.\nV13.1 Configuration Documentation\nThis section outlines documentation requirements for how the application communicates with in‑\nternal and external services, as well as techniques to prevent loss of availability due to service inac‑\ncessibility. It also addresses documentation related to secrets.\n#\nDescription\nLevel\n13.1.1\nVerify that all communication needs for the application are documented.\nThis must include external services which the application relies upon and\ncases where an end user might be able to provide an external location to\nwhich the application will then connect.\n2\n13.1.2\nVerify that for each service the application uses, the documentation defines\nthe maximum number of concurrent connections (e.g., connection pool\nlimits) and how the application behaves when that limit is reached,\nincluding any fallback or recovery mechanisms, to prevent denial of service\nconditions.\n3\n13.1.3\nVerify that the application documentation defines resource‑management\nstrategies for every external system or service it uses (e.g., databases, file\nhandles, threads, HTTP connections). This should include resource‑release\nprocedures, timeout settings, failure handling, and where retry logic is\nimplemented, specifying retry limits, delays, and back‑off algorithms. For\nsynchronous HTTP request–response operations it should mandate short\ntimeouts and either disable retries or strictly limit retries to prevent\ncascading delays and resource exhaustion.\n3\n13.1.4\nVerify that the application’s documentation defines the secrets that are\ncritical for the security of the application and a schedule for rotating them,\nbased on the organization’s threat model and business requirements.\n3\nV13.2 Backend Communication Configuration\nApplications interact with multiple services, including APIs, databases, or other components. These\nmay be considered internal to the application but not included in the application’s standard access\ncontrol mechanisms, or they may be entirely external. In either case, it is necessary to configure the\napplication to interact securely with these components and, if required, protect that configuration.\n78",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 72
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nNote: The “Secure Communication”chapter provides guidance for encryption in transit.\n#\nDescription\nLevel\n13.2.1\nVerify that communications between backend application components that\ndon’t support the application’s standard user session mechanism, including\nAPIs, middleware, and data layers, are authenticated. Authentication must\nuse individual service accounts, short‑term tokens, or certificate‑based\nauthentication and not unchanging credentials such as passwords, API keys,\nor shared accounts with privileged access.\n2\n13.2.2\nVerify that communications between backend application components,\nincluding local or operating system services, APIs, middleware, and data\nlayers, are performed with accounts assigned the least necessary privileges.\n2\n13.2.3\nVerify that if a credential has to be used for service authentication, the\ncredential being used by the consumer is not a default credential (e.g.,\nroot/root or admin/admin).\n2\n13.2.4\nVerify that an allowlist is used to define the external resources or systems\nwith which the application is permitted to communicate (e.g., for outbound\nrequests, data loads, or file access). This allowlist can be implemented at the\napplication layer, web server, firewall, or a combination of different layers.\n2\n13.2.5\nVerify that the web or application server is configured with an allowlist of\nresources or systems to which the server can send requests or load data or\nfiles from.\n2\n13.2.6\nVerify that where the application connects to separate services, it follows the\ndocumented configuration for each connection, such as maximum parallel\nconnections, behavior when maximum allowed connections is reached,\nconnection timeouts, and retry strategies.\n3\nV13.3 Secret Management\nSecret management is an essential configuration task to ensure the protection of data used in the\napplication. Specific requirements for cryptography can be found in the “Cryptography”chapter, but\nthis section focuses on the management and handling aspects of secrets.\n79",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 73
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n13.3.1\nVerify that a secrets management solution, such as a key vault, is used to\nsecurely create, store, control access to, and destroy backend secrets. These\ncould include passwords, key material, integrations with databases and\nthird‑party systems, keys and seeds for time‑based tokens, other internal\nsecrets, and API keys. Secrets must not be included in application source\ncode or included in build artifacts. For an L3 application, this must involve a\nhardware‑backed solution such as an HSM.\n2\n13.3.2\nVerify that access to secret assets adheres to the principle of least privilege.\n2\n13.3.3\nVerify that all cryptographic operations are performed using an isolated\nsecurity module (such as a vault or hardware security module) to securely\nmanage and protect key material from exposure outside of the security\nmodule.\n3\n13.3.4\nVerify that secrets are configured to expire and be rotated based on the\napplication’s documentation.\n3\nV13.4 Unintended Information Leakage\nProduction configurations should be hardened to avoid disclosing unnecessary data. Many of these\nissues are rarely rated as significant risks but are often chained with other vulnerabilities. If these\nissues are not present by default, it raises the bar for attacking an application.\nFor example, hiding the version of server‑side components does not eliminate the need to patch all\ncomponents, and disabling folder listing does not remove the need to use authorization controls or\nkeep files away from the public folder, but it raises the bar.\n#\nDescription\nLevel\n13.4.1\nVerify that the application is deployed either without any source control\nmetadata, including the .git or .svn folders, or in a way that these folders are\ninaccessible both externally and to the application itself.\n1\n13.4.2\nVerify that debug modes are disabled for all components in production\nenvironments to prevent exposure of debugging features and information\nleakage.\n2\n13.4.3\nVerify that web servers do not expose directory listings to clients unless\nexplicitly intended.\n2\n13.4.4\nVerify that using the HTTP TRACE method is not supported in production\nenvironments, to avoid potential information leakage.\n2\n80",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 74
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n13.4.5\nVerify that documentation (such as for internal APIs) and monitoring\nendpoints are not exposed unless explicitly intended.\n2\n13.4.6\nVerify that the application does not expose detailed version information of\nbackend components.\n3\n13.4.7\nVerify that the web tier is configured to only serve files with specific file\nextensions to prevent unintentional information, configuration, and source\ncode leakage.\n3\nReferences\nFor more information, see also:\n• OWASP Web Security Testing Guide: Configuration and Deployment Management Testing\nV14 Data Protection\nControl Objective\nApplications cannot account for all usage patterns and user behaviors, and should therefore imple‑\nment controls to limit unauthorized access to sensitive data on client devices.\nThis chapter includes requirements related to defining what data needs to be protected, how it should\nbe protected, and specific mechanisms to implement or pitfalls to avoid.\nAnother consideration for data protection is bulk extraction, modification, or excessive usage. Each\nsystem’s requirements are likely to be very different, so determining what is “abnormal”must con‑\nsider the threat model and business risk. From an ASVS perspective, detecting these issues is handled\nin the “Security Logging and Error Handling”chapter, and setting limits is handled in the “Validation\nand Business Logic”chapter.\nV14.1 Data Protection Documentation\nA key prerequisite for being able to protect data is to categorize what data should be considered\nsensitive. There are likely to be several different levels of sensitivity, and for each level, the controls\nrequired to protect data at that level will be different.\nThere are various privacy regulations and laws that affect how applications must approach the stor‑\nage, use, and transmission of sensitive personal information. This section no longer tries to duplicate\n81",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 75
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nthese types of data protection or privacy legislation, but rather focuses on key technical considera‑\ntions for protecting sensitive data. Please consult local laws and regulations, and consult a qualified\nprivacy specialist or lawyer as required.\n#\nDescription\nLevel\n14.1.1\nVerify that all sensitive data created and processed by the application has\nbeen identified and classified into protection levels. This includes data that is\nonly encoded and therefore easily decoded, such as Base64 strings or the\nplaintext payload inside a JWT. Protection levels need to take into account\nany data protection and privacy regulations and standards which the\napplication is required to comply with.\n2\n14.1.2\nVerify that all sensitive data protection levels have a documented set of\nprotection requirements. This must include (but not be limited to)\nrequirements related to general encryption, integrity verification, retention,\nhow the data is to be logged, access controls around sensitive data in logs,\ndatabase‑level encryption, privacy and privacy‑enhancing technologies to be\nused, and other confidentiality requirements.\n2\nV14.2 General Data Protection\nThis section contains various practical requirements related to the protection of data. Most are spe‑\ncific to particular issues such as unintended data leakage, but there is also a general requirement to\nimplement protection controls based on the protection level required for each data item.\n#\nDescription\nLevel\n14.2.1\nVerify that sensitive data is only sent to the server in the HTTP message body\nor header fields, and that the URL and query string do not contain sensitive\ninformation, such as an API key or session token.\n1\n14.2.2\nVerify that the application prevents sensitive data from being cached in\nserver components, such as load balancers and application caches, or\nensures that the data is securely purged after use.\n2\n14.2.3\nVerify that defined sensitive data is not sent to untrusted parties (e.g., user\ntrackers) to prevent unwanted collection of data outside of the application’s\ncontrol.\n2\n82",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 76
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n14.2.4\nVerify that controls around sensitive data related to encryption, integrity\nverification, retention, how the data is to be logged, access controls around\nsensitive data in logs, privacy and privacy‑enhancing technologies, are\nimplemented as defined in the documentation for the specific data’s\nprotection level.\n2\n14.2.5\nVerify that caching mechanisms are configured to only cache responses\nwhich have the expected content type for that resource and do not contain\nsensitive, dynamic content. The web server should return a 404 or 302\nresponse when a non‑existent file is accessed rather than returning a\ndifferent, valid file. This should prevent Web Cache Deception attacks.\n3\n14.2.6\nVerify that the application only returns the minimum required sensitive data\nfor the application’s functionality. For example, only returning some of the\ndigits of a credit card number and not the full number. If the complete data\nis required, it should be masked in the user interface unless the user\nspecifically views it.\n3\n14.2.7\nVerify that sensitive information is subject to data retention classification,\nensuring that outdated or unnecessary data is deleted automatically, on a\ndefined schedule, or as the situation requires.\n3\n14.2.8\nVerify that sensitive information is removed from the metadata of\nuser‑submitted files unless storage is consented to by the user.\n3\nV14.3 Client‑side Data Protection\nThis section contains requirements preventing data from leaking in specific ways at the client or user\nagent side of an application.\n#\nDescription\nLevel\n14.3.1\nVerify that authenticated data is cleared from client storage, such as the\nbrowser DOM, after the client or session is terminated. The ‘Clear‑Site‑Data’\nHTTP response header field may be able to help with this but the client‑side\nshould also be able to clear up if the server connection is not available when\nthe session is terminated.\n1\n14.3.2\nVerify that the application sets sufficient anti‑caching HTTP response header\nfields (i.e., Cache‑Control: no‑store) so that sensitive data is not cached in\nbrowsers.\n2\n83",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 77
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n14.3.3\nVerify that data stored in browser storage (such as localStorage,\nsessionStorage, IndexedDB, or cookies) does not contain sensitive data, with\nthe exception of session tokens.\n2\nReferences\nFor more information, see also:\n• Consider using the Security Headers website to check security and anti‑caching header fields\n• Documentation about anti‑caching headers by Mozilla\n• OWASP Secure Headers project\n• OWASP Privacy Risks Project\n• OWASP User Privacy Protection Cheat Sheet\n• Australian Privacy Principle 11 ‑ Security of personal information\n• European Union General Data Protection Regulation (GDPR) overview\n• European Union Data Protection Supervisor ‑ Internet Privacy Engineering Network\n• Information on the “Clear‑Site‑Data”header\n• White paper on Web Cache Deception\nV15 Secure Coding and Architecture\nControl Objective\nMany ASVS requirements either relate to a particular area of security, such as authentication or au‑\nthorization, or pertain to a particular type of application functionality, such as logging or file han‑\ndling.\nThis chapter provides general security requirements to consider when designing and developing ap‑\nplications. These requirements focus not only on clean architecture and code quality but also on\nspecific architecture and coding practices necessary for application security.\nV15.1 Secure Coding and Architecture Documentation\nMany requirements for establishing a secure and defensible architecture depend on clear documen‑\ntation of decisions made regarding the implementation of specific security controls and the compo‑\nnents used within the application.\nThis section outlines the documentation requirements, including identifying components consid‑\nered to contain “dangerous functionality”or to be “risky components.”\n84",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 78
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nA component with “dangerous functionality”may be an internally developed or third‑party compo‑\nnent that performs operations such as deserialization of untrusted data, raw file or binary data pars‑\ning, dynamic code execution, or direct memory manipulation. Vulnerabilities in these types of op‑\nerations pose a high risk of compromising the application and potentially exposing its underlying\ninfrastructure.\nA “risky component”is a 3rd party library (i.e., not internally developed) with missing or poorly im‑\nplemented security controls around its development processes or functionality. Examples include\ncomponents that are poorly maintained, unsupported, at the end‑of‑life stage, or have a history of\nsignificant vulnerabilities.\nThis section also emphasizes the importance of defining appropriate timeframes for addressing vul‑\nnerabilities in third‑party components.\n#\nDescription\nLevel\n15.1.1\nVerify that application documentation defines risk based remediation time\nframes for 3rd party component versions with vulnerabilities and for\nupdating libraries in general, to minimize the risk from these components.\n1\n15.1.2\nVerify that an inventory catalog, such as software bill of materials (SBOM), is\nmaintained of all third‑party libraries in use, including verifying that\ncomponents come from pre‑defined, trusted, and continually maintained\nrepositories.\n2\n15.1.3\nVerify that the application documentation identifies functionality which is\ntime‑consuming or resource‑demanding. This must include how to prevent\na loss of availability due to overusing this functionality and how to avoid a\nsituation where building a response takes longer than the consumer’s\ntimeout. Potential defenses may include asynchronous processing, using\nqueues, and limiting parallel processes per user and per application.\n2\n15.1.4\nVerify that application documentation highlights third‑party libraries which\nare considered to be “risky components”.\n3\n15.1.5\nVerify that application documentation highlights parts of the application\nwhere “dangerous functionality”is being used.\n3\nV15.2 Security Architecture and Dependencies\nThis section includes requirements for handling risky, outdated, or insecure dependencies and com‑\nponents through dependency management.\nIt also includes using architectural‑level techniques such as sandboxing, encapsulation, container‑\nization, and network isolation to reduce the impact of using “dangerous operations”or “risky compo‑\n85",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 79
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nnents”(as defined in the previous section) and prevent loss of availability due to overusing resource‑\ndemanding functionality.\n#\nDescription\nLevel\n15.2.1\nVerify that the application only contains components which have not\nbreached the documented update and remediation time frames.\n1\n15.2.2\nVerify that the application has implemented defenses against loss of\navailability due to functionality which is time‑consuming or\nresource‑demanding, based on the documented security decisions and\nstrategies for this.\n2\n15.2.3\nVerify that the production environment only includes functionality that is\nrequired for the application to function, and does not expose extraneous\nfunctionality such as test code, sample snippets, and development\nfunctionality.\n2\n15.2.4\nVerify that third‑party components and all of their transitive dependencies\nare included from the expected repository, whether internally owned or an\nexternal source, and that there is no risk of a dependency confusion attack.\n3\n15.2.5\nVerify that the application implements additional protections around parts\nof the application which are documented as containing “dangerous\nfunctionality”or using third‑party libraries considered to be “risky\ncomponents”. This could include techniques such as sandboxing,\nencapsulation, containerization or network level isolation to delay and deter\nattackers who compromise one part of an application from pivoting\nelsewhere in the application.\n3\nV15.3 Defensive Coding\nThis section covers vulnerability types, including type juggling, prototype pollution, and others,\nwhich result from using insecure coding patterns in a particular language. Some may not be relevant\nto all languages, whereas others will have language‑specific fixes or may relate to how a particular\nlanguage or framework handles a feature such as HTTP parameters. It also considers the risk of not\ncryptographically validating application updates.\nIt also considers the risks associated with using objects to represent data items and accepting and\nreturning these via external APIs. In this case, the application must ensure that data fields that should\nnot be writable are not modified by user input (mass assignment) and that the API is selective about\nwhat data fields get returned. Where field access depends on a user’s permissions, this should be\nconsidered in the context of the field‑level access control requirement in the Authorization chapter.\n86",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 80
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n15.3.1\nVerify that the application only returns the required subset of fields from a\ndata object. For example, it should not return an entire data object, as some\nindividual fields should not be accessible to users.\n1\n15.3.2\nVerify that where the application backend makes calls to external URLs, it is\nconfigured to not follow redirects unless it is intended functionality.\n2\n15.3.3\nVerify that the application has countermeasures to protect against mass\nassignment attacks by limiting allowed fields per controller and action, e.g.,\nit is not possible to insert or update a field value when it was not intended to\nbe part of that action.\n2\n15.3.4\nVerify that all proxying and middleware components transfer the user’s\noriginal IP address correctly using trusted data fields that cannot be\nmanipulated by the end user, and the application and web server use this\ncorrect value for logging and security decisions such as rate limiting, taking\ninto account that even the original IP address may not be reliable due to\ndynamic IPs, VPNs, or corporate firewalls.\n2\n15.3.5\nVerify that the application explicitly ensures that variables are of the correct\ntype and performs strict equality and comparator operations. This is to avoid\ntype juggling or type confusion vulnerabilities caused by the application\ncode making an assumption about a variable type.\n2\n15.3.6\nVerify that JavaScript code is written in a way that prevents prototype\npollution, for example, by using Set() or Map() instead of object literals.\n2\n15.3.7\nVerify that the application has defenses against HTTP parameter pollution\nattacks, particularly if the application framework makes no distinction about\nthe source of request parameters (query string, body parameters, cookies, or\nheader fields).\n2\nV15.4 Safe Concurrency\nConcurrency issues such as race conditions, time‑of‑check to time‑of‑use (TOCTOU) vulnerabilities,\ndeadlocks, livelocks, thread starvation, and improper synchronization can lead to unpredictable be‑\nhavior and security risks. This section includes various techniques and strategies to help mitigate\nthese risks.\n87",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 81
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n15.4.1\nVerify that shared objects in multi‑threaded code (such as caches, files, or\nin‑memory objects accessed by multiple threads) are accessed safely by\nusing thread‑safe types and synchronization mechanisms like locks or\nsemaphores to avoid race conditions and data corruption.\n3\n15.4.2\nVerify that checks on a resource’s state, such as its existence or permissions,\nand the actions that depend on them are performed as a single atomic\noperation to prevent time‑of‑check to time‑of‑use (TOCTOU) race conditions.\nFor example, checking if a file exists before opening it, or verifying a user’s\naccess before granting it.\n3\n15.4.3\nVerify that locks are used consistently to avoid threads getting stuck, whether\nby waiting on each other or retrying endlessly, and that locking logic stays\nwithin the code responsible for managing the resource to ensure locks\ncannot be inadvertently or maliciously modified by external classes or code.\n3\n15.4.4\nVerify that resource allocation policies prevent thread starvation by ensuring\nfair access to resources, such as by leveraging thread pools, allowing\nlower‑priority threads to proceed within a reasonable timeframe.\n3\nReferences\nFor more information, see also:\n• OWASP Prototype Pollution Prevention Cheat Sheet\n• OWASP Mass Assignment Prevention Cheat Sheet\n• OWASP CycloneDX Bill of Materials Specification\n• OWASP Web Security Testing Guide: Testing for HTTP Parameter Pollution\nV16 Security Logging and Error Handling\nControl Objective\nSecurity logs are distinct from error or performance logs and are used to record security‑relevant\nevents such as authentication decisions, access control decisions, and attempts to bypass security\ncontrols, such as input validation or business logic validation. Their purpose is to support detection,\nresponse, and investigation by providing high‑signal, structured data for analysis tools like SIEMs.\nLogs should not include sensitive personal data unless legally required, and any logged data must be\nprotected as a high‑value asset. Logging must not compromise privacy or system security. Applica‑\ntions must also fail securely, avoiding unnecessary disclosure or disruption.\n88",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 82
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nFor detailed implementation guidance, refer to the OWASP Cheat Sheets in the references section.\nV16.1 Security Logging Documentation\nThis section ensures a clear and complete inventory of logging across the application stack. This is\nessential for effective security monitoring, incident response, and compliance.\n#\nDescription\nLevel\n16.1.1\nVerify that an inventory exists documenting the logging performed at each\nlayer of the application’s technology stack, what events are being logged, log\nformats, where that logging is stored, how it is used, how access to it is\ncontrolled, and for how long logs are kept.\n2\nV16.2 General Logging\nThis section provides requirements to ensure that security logs are consistently structured and con‑\ntain the expected metadata. The goal is to make logs machine‑readable and analyzable across dis‑\ntributed systems and tools.\nNaturally, security events often involve sensitive data. If such data is logged without consideration,\nthe logs themselves become classified and therefore subject to encryption requirements, stricter re‑\ntention policies, and potential disclosure during audits.\nTherefore, it is critical to log only what is necessary and to treat log data with the same care as other\nsensitive assets.\nThe requirements below establish foundational requirements for logging metadata, synchroniza‑\ntion, format, and control.\n#\nDescription\nLevel\n16.2.1\nVerify that each log entry includes necessary metadata (such as when,\nwhere, who, what) that would allow for a detailed investigation of the\ntimeline when an event happens.\n2\n16.2.2\nVerify that time sources for all logging components are synchronized, and\nthat timestamps in security event metadata use UTC or include an explicit\ntime zone offset. UTC is recommended to ensure consistency across\ndistributed systems and to prevent confusion during daylight saving time\ntransitions.\n2\n16.2.3\nVerify that the application only stores or broadcasts logs to the files and\nservices that are documented in the log inventory.\n2\n89",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 83
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n16.2.4\nVerify that logs can be read and correlated by the log processor that is in use,\npreferably by using a common logging format.\n2\n16.2.5\nVerify that when logging sensitive data, the application enforces logging\nbased on the data’s protection level. For example, it may not be allowed to\nlog certain data, such as credentials or payment details. Other data, such as\nsession tokens, may only be logged by being hashed or masked, either in full\nor partially.\n2\nV16.3 Security Events\nThis section defines requirements for logging security‑relevant events within the application. Cap‑\nturing these events is critical for detecting suspicious behavior, supporting investigations, and ful‑\nfilling compliance obligations.\nThis section outlines the types of events that should be logged but does not attempt to provide ex‑\nhaustive detail. Each application has unique risk factors and operational context.\nNote that while ASVS includes logging of security events in scope, alerting and correlation (e.g., SIEM\nrules or monitoring infrastructure) are considered out of scope and are handled by operational and\nmonitoring systems.\n#\nDescription\nLevel\n16.3.1\nVerify that all authentication operations are logged, including successful and\nunsuccessful attempts. Additional metadata, such as the type of\nauthentication or factors used, should also be collected.\n2\n16.3.2\nVerify that failed authorization attempts are logged. For L3, this must\ninclude logging all authorization decisions, including logging when sensitive\ndata is accessed (without logging the sensitive data itself).\n2\n16.3.3\nVerify that the application logs the security events that are defined in the\ndocumentation and also logs attempts to bypass the security controls, such\nas input validation, business logic, and anti‑automation.\n2\n16.3.4\nVerify that the application logs unexpected errors and security control\nfailures such as backend TLS failures.\n2\n90",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 84
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nV16.4 Log Protection\nLogs are valuable forensic artifacts and must be protected. If logs can be easily modified or deleted,\nthey lose their integrity and become unreliable for incident investigations or legal proceedings. Logs\nmay expose internal application behavior or sensitive metadata, making them an attractive target for\nattackers.\nThis section defines requirements to ensure that logs are protected from unauthorized access, tam‑\npering, and disclosure, and that they are safely transmitted and stored in secure, isolated systems.\n#\nDescription\nLevel\n16.4.1\nVerify that all logging components appropriately encode data to prevent log\ninjection.\n2\n16.4.2\nVerify that logs are protected from unauthorized access and cannot be\nmodified.\n2\n16.4.3\nVerify that logs are securely transmitted to a logically separate system for\nanalysis, detection, alerting, and escalation. The aim is to ensure that if the\napplication is breached, the logs are not compromised.\n2\nV16.5 Error Handling\nThis section defines requirements to ensure that applications fail gracefully and securely without\ndisclosing sensitive internal details.\n#\nDescription\nLevel\n16.5.1\nVerify that a generic message is returned to the consumer when an\nunexpected or security‑sensitive error occurs, ensuring no exposure of\nsensitive internal system data such as stack traces, queries, secret keys, and\ntokens.\n2\n16.5.2\nVerify that the application continues to operate securely when external\nresource access fails, for example, by using patterns such as circuit breakers\nor graceful degradation.\n2\n16.5.3\nVerify that the application fails gracefully and securely, including when an\nexception occurs, preventing fail‑open conditions such as processing a\ntransaction despite errors resulting from validation logic.\n2\n91",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 85
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n16.5.4\nVerify that a “last resort”error handler is defined which will catch all\nunhandled exceptions. This is both to avoid losing error details that must go\nto log files and to ensure that an error does not take down the entire\napplication process, leading to a loss of availability.\n3\nNote: Certain languages, (including Swift, Go, and through common design practice, many func‑\ntional languages,) do not support exceptions or last‑resort event handlers. In this case, architects\nand developers should use a pattern, language, or framework‑friendly way to ensure that applica‑\ntions can securely handle exceptional, unexpected, or security‑related events.\nReferences\nFor more information, see also:\n• OWASP Web Security Testing Guide: Testing for Error Handling\n• OWASP Authentication Cheat Sheet section about error messages\n• OWASP Logging Cheat Sheet\n• OWASP Application Logging Vocabulary Cheat Sheet\nV17 WebRTC\nControl Objective\nWeb Real‑Time Communication (WebRTC) enables real‑time voice, video, and data exchange in mod‑\nern applications. As adoption increases, securing WebRTC infrastructure becomes critical. This\nsection provides security requirements for stakeholders who develop, host, or integrate WebRTC\nsystems.\nThe WebRTC market can be broadly categorized into three segments:\n1. Product Developers: Proprietary and open‑source vendors that create and supply WebRTC\nproducts and solutions. Their focus is on developing robust and secure WebRTC technologies\nthat can be used by others.\n2. Communication Platforms as a Service (CPaaS): Providers that offer APIs, SDKs, and the nec‑\nessary infrastructure or platforms to enable WebRTC functionalities. CPaaS providers may use\nproducts from the first category or develop their own WebRTC software to offer these services.\n3. Service Providers: Organizations that leverage products from product developers or CPaaS\nproviders, or develop their own WebRTC solutions. They create and implement applications\n92",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 86
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nfor online conferencing, healthcare, e‑learning, and other domains where real‑time commu‑\nnication is crucial.\nThe security requirements outlined here are primarily focused on Product Developers, CPaaS, and\nService Providers who:\n• Utilize open‑source solutions to build their WebRTC applications.\n• Use commercial WebRTC products as part of their infrastructure.\n• Use internally developed WebRTC solutions or integrate various components into a cohesive\nservice offering.\nIt is important to note that these security requirements do not apply to developers who exclusively\nuse SDKs and APIs provided by CPaaS vendors. For such developers, the CPaaS providers are typi‑\ncally responsible for most of the underlying security concerns within their platforms, and a generic\nsecurity standard like ASVS may not fully address their needs.\nV17.1 TURN Server\nThis section defines security requirements for systems that operate their own TURN (Traversal Us‑\ning Relays around NAT) servers. TURN servers assist in relaying media in restrictive network envi‑\nronments but can pose risks if misconfigured. These controls focus on secure address filtering and\nprotection against resource exhaustion.\n#\nDescription\nLevel\n17.1.1\nVerify that the Traversal Using Relays around NAT (TURN) service only\nallows access to IP addresses that are not reserved for special purposes (e.g.,\ninternal networks, broadcast, loopback). Note that this applies to both IPv4\nand IPv6 addresses.\n2\n17.1.2\nVerify that the Traversal Using Relays around NAT (TURN) service is not\nsusceptible to resource exhaustion when legitimate users attempt to open a\nlarge number of ports on the TURN server.\n3\nV17.2 Media\nThese requirements only apply to systems that host their own WebRTC media servers, such as Selec‑\ntive Forwarding Units (SFUs), Multipoint Control Units (MCUs), recording servers, or gateway servers.\nMedia servers handle and distribute media streams, making their security critical to protect commu‑\nnication between peers. Safeguarding media streams is paramount in WebRTC applications to pre‑\nvent eavesdropping, tampering, and denial‑of‑service attacks that could compromise user privacy\nand communication quality.\n93",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 87
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nIn particular, it is necessary to implement protections against flood attacks such as rate limiting, val‑\nidating timestamps, using synchronized clocks to match real‑time intervals, and managing buffers\nto prevent overflow and maintain proper timing. If packets for a particular media session arrive too\nquickly, excess packets should be dropped. It is also important to protect the system from malformed\npackets by implementing input validation, safely handling integer overflows, preventing buffer over‑\nflows, and employing other robust error‑handling techniques.\nSystems that rely solely on peer‑to‑peer media communication between web browsers, without the\ninvolvement of intermediate media servers, are excluded from these specific media‑related security\nrequirements.\nThis section refers to the use of Datagram Transport Layer Security (DTLS) in the context of WebRTC.\nA requirement related to having a documented policy for the management of cryptographic keys can\nbe found in the “Cryptography”chapter. Information on approved cryptographic methods can be\nfound either in the Cryptography Appendix of the ASVS or in documents such as NIST SP 800‑52\nRev. 2 or BSI TR‑02102‑2 (Version 2025‑01).\n#\nDescription\nLevel\n17.2.1\nVerify that the key for the Datagram Transport Layer Security (DTLS)\ncertificate is managed and protected based on the documented policy for\nmanagement of cryptographic keys.\n2\n17.2.2\nVerify that the media server is configured to use and support approved\nDatagram Transport Layer Security (DTLS) cipher suites and a secure\nprotection profile for the DTLS Extension for establishing keys for the Secure\nReal‑time Transport Protocol (DTLS‑SRTP).\n2\n17.2.3\nVerify that Secure Real‑time Transport Protocol (SRTP) authentication is\nchecked at the media server to prevent Real‑time Transport Protocol (RTP)\ninjection attacks from leading to either a Denial of Service condition or\naudio or video media insertion into media streams.\n2\n17.2.4\nVerify that the media server is able to continue processing incoming media\ntraffic when encountering malformed Secure Real‑time Transport Protocol\n(SRTP) packets.\n2\n17.2.5\nVerify that the media server is able to continue processing incoming media\ntraffic during a flood of Secure Real‑time Transport Protocol (SRTP) packets\nfrom legitimate users.\n3\n17.2.6\nVerify that the media server is not susceptible to the “ClientHello”Race\nCondition vulnerability in Datagram Transport Layer Security (DTLS) by\nchecking if the media server is publicly known to be vulnerable or by\nperforming the race condition test.\n3\n94",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 88
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n#\nDescription\nLevel\n17.2.7\nVerify that any audio or video recording mechanisms associated with the\nmedia server are able to continue processing incoming media traffic during\na flood of Secure Real‑time Transport Protocol (SRTP) packets from\nlegitimate users.\n3\n17.2.8\nVerify that the Datagram Transport Layer Security (DTLS) certificate is\nchecked against the Session Description Protocol (SDP) fingerprint attribute,\nterminating the media stream if the check fails, to ensure the authenticity of\nthe media stream.\n3\nV17.3 Signaling\nThis section defines requirements for systems that operate their own WebRTC signaling servers. Sig‑\nnaling coordinates peer‑to‑peer communication and must be resilient against attacks that could dis‑\nrupt session establishment or control.\nTo ensure secure signaling, systems must handle malformed inputs gracefully and remain available\nunder load.\n#\nDescription\nLevel\n17.3.1\nVerify that the signaling server is able to continue processing legitimate\nincoming signaling messages during a flood attack. This should be achieved\nby implementing rate limiting at the signaling level.\n2\n17.3.2\nVerify that the signaling server is able to continue processing legitimate\nsignaling messages when encountering malformed signaling message that\ncould cause a denial of service condition. This could include implementing\ninput validation, safely handling integer overflows, preventing buffer\noverflows, and employing other robust error‑handling techniques.\n2\nReferences\nFor more information, see also:\n• The WebRTC DTLS ClientHello DoS is best documented at Enable Security’s blog post aimed at\nsecurity professionals and the associated white paper aimed at WebRTC developers\n• RFC 3550 ‑ RTP: A Transport Protocol for Real‑Time Applications\n• RFC 3711 ‑ The Secure Real‑time Transport Protocol (SRTP)\n• RFC 5764 ‑ Datagram Transport Layer Security (DTLS) Extension to Establish Keys for the Secure\nReal‑time Transport Protocol (SRTP))\n95",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 89
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• RFC 8825 ‑ Overview: Real‑Time Protocols for Browser‑Based Applications\n• RFC 8826 ‑ Security Considerations for WebRTC\n• RFC 8827 ‑ WebRTC Security Architecture\n• DTLS‑SRTP Protection Profiles\nAppendix A: Glossary\n• Absolute Maximum Session Lifetime –Also referred to as “Overall Timeout”by NIST, this is the\nmaximal amount of time a session can remain active following authentication regardless of\nuser interaction. This is a component of session expiration.\n• Allowlist –A list of permitted data or operations, for example, a list of characters that are al‑\nlowed to perform input validation.\n• Anti‑forgery token –A mechanism by which one or more tokens are passed in a request and\nvalidated by the application server to ensure that the request has come from an expected end‑\npoint.\n• Application Security –Application‑level security focuses on the analysis of components that\ncomprise the application layer of the Open Systems Interconnection Reference Model (OSI\nModel), rather than focusing on for example the underlying operating system or connected\nnetworks.\n• Application Security Verification –The technical assessment of an application against the\nOWASP ASVS.\n• Application Security Verification Report –A report that documents the overall results and sup‑\nporting analysis produced by the verifier for a particular application.\n• Authentication –The verification of the claimed identity of an application user.\n• Automated Verification –The use of automated tools (either dynamic analysis tools, static anal‑\nysis tools, or both) that use vulnerability signatures to find problems.\n• Black box testing –A method of software testing that examines the functionality of an applica‑\ntion without peering into its internal structures or workings.\n• Common Weakness Enumeration (CWE) –A community‑developed list of common software\nsecurity weaknesses. It serves as a common language, a measuring stick for software security\ntools, and a baseline for weakness identification, mitigation, and prevention efforts.\n• Component –A self‑contained unit of code, with associated disk and network interfaces that\ncommunicates with other components.\n• Credential Service Provider (CSP) –Also called an Identity Provider (IdP). A source of user data\nwhich may be used as an authentication source by other applications.\n• Cross‑Site Script Inclusion (XSSI) ‑ A variant of Cross‑Site Scripting (XSS) attack in which a web\napplication retrieves malicious code from an external resource and includes that code as part\nof its own content.\n• Cross‑Site Scripting (XSS) –A security vulnerability typically found in web applications allow‑\ning the injection of client‑side scripts into content.\n96",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 90
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• Cryptographic module –Hardware, software, and/or firmware that implements cryptographic\nalgorithms and/or generates cryptographic keys.\n• Cryptographically secure pseudo‑random number generator (CSPRNG) ‑ A pseudorandom\nnumber generator with properties that make it suitable for use in cryptography, also referred\nto as a cryptographic random number generator (CRNG).\n• Datagram Transport Layer Security (DTLS) –A cryptographic protocol which provides com‑\nmunication security over a network connection. It is based on the TLS protocol but adapted for\nprotecting datagram‑oriented protocols (usually over UDP). Defined in RFC 9147 for DTLS 1.3.\n• Datagram Transport Layer Security Extension to Establish Keys for the Secure Real‑time\nTransport Protocol (DTLS‑SRTP) –A mechanism for using a DTLS handshake for establishing\nkey material for a SRTP session. Defined in RFC 5764.\n• Design Verification –The technical assessment of the security architecture of an application.\n• Dynamic Application Security Testing (DAST) –Technologies are designed to detect conditions\nindicative of a security vulnerability in an application in its running state.\n• Dynamic Verification –The use of automated tools that use vulnerability signatures to find\nproblems during the execution of an application.\n• Fast IDentity Online (FIDO) –A set of authentication standards that allow a variety of different\nauthentication methods to be used including biometrics, Trusted Platform Modules (TPMs),\nUSB security tokens, etc.\n• Hardware Security Module (HSM) –Hardware component that stores cryptographic keys and\nother secrets in a protected manner.\n• Hibernate Query Language (HQL) –A query language that is similar in appearance to SQL used\nby the Hibernate ORM library.\n• HTTP Strict Transport Security (HSTS) –An policy which instructs the browser to only connect\nto the domain returning the header via TLS and when a valid certificate is presented. It is\nactivated using the Strict‑Transport‑Security response header field.\n• HyperText Transfer Protocol (HTTP) –An application protocol for distributed, collaborative,\nhypermedia information systems. It is the foundation of data communication for the World\nWide Web.\n• HyperText Transfer Protocol over SSL/TLS (HTTPS) –A method of securing HTTP communi‑\ncation by encrypting it using Transport Layer Security (TLS).\n• Identity Provider (IdP) –Also called a Credential Service Provider (CSP) in NIST references. An\nentity that provides an authentication source for other applications.\n• Inactivity Timeout –This is the length of time a session can remain active in the absence of\nuser interaction with the application. This is a component of session expiration.\n• Input Validation –The canonicalization and validation of untrusted user input.\n• JSON Web Token (JWT) –RFC 7519 defines a standard for a JSON data object made up of a header\nsection which explains how to validate the object, a body section containing a set of claims, and\na signature section which contains a digital signature which can be used to validate the contents\nof the body section. It is a type of self‑contained token.\n• Local File Inclusion (LFI) ‑ An attack that exploits vulnerable file inclusion procedures in an\n97",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 91
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\napplication, leading to the inclusion of local files already present on the server.\n• Malicious Code –Code introduced into an application during its development unbeknownst to\nthe application owner, which circumvents the application’s intended security policy. Not the\nsame as malware such as a virus or worm!\n• Malware –Executable code that is introduced into an application during runtime without the\nknowledge of the application user or administrator.\n• Message authentication code (MAC) ‑ A cryptographic checksum on data, computed by a MAC\ngeneration algorithm, that is used to provide assurance on its integrity and authenticity.\n• Multi‑factor authentication (MFA) –Authentication which includes two or more of the single\nfactors.\n• Mutual TLS (mTLS) –See TLS client authentication.\n• Object‑relational Mapping (ORM) –A system used to allow a relational/table‑based database\nto be referenced and queried within an application program using an application‑compatible\nobject model.\n• One‑time Password (OTP) –A password that is uniquely generated to be used on a single occa‑\nsion.\n• Open Worldwide Application Security Project (OWASP) –The Open Worldwide Application\nSecurity Project (OWASP) is a worldwide free and open community focused on improving the\nsecurity of application software. Our mission is to make application security “visible,”so that\npeople and organizations can make informed decisions about application security risks. See:\nhttps://www.owasp.org/.\n• Password‑Based Key Derivation Function 2 (PBKDF2) –A special one‑way algorithm used to\ncreate a strong cryptographic key from an input text (such as a password) and an additional\nrandom salt value and can therefore be used to make it harder to crack a password offline if the\nresulting value is stored instead of the original password.\n• Public Key Infrastructure (PKI) –An arrangement that binds public keys with respective iden‑\ntities of entities. The binding is established through a process of registration and issuance of\ncertificates at and by a certificate authority (CA).\n• Public Switched Telephone Network (PSTN) –The traditional telephone network that includes\nboth fixed‑line telephones and mobile telephones.\n• Real‑time Transport Protocol (RTP) and Real‑time Transport Control Protocol (RTCP) –Two\nprotocols used in association for transporting multimedia streams. Used by the WebRTC stack.\nDefined in RFC 3550.\n• Reference Token –A type of token that acts as a pointer or identifier to state or metadata stored\non a server, sometimes referred to as random tokens or opaque tokens. Unlike self‑contained\ntokens, which embed some of their relevant data within the token itself, reference tokens con‑\ntain no intrinsic information, instead relying on the server for context. The reference token\nwill either be or contain a session identifier.\n• Relying Party (RP) –Generally an application which is relying on a user having authenticated\nagainst a separate authentication provider. The application relies on some sort of token or set\nof signed assertions provided by that authentication provider to trust that the user is who they\n98",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 92
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nsay they are.\n• Remote File Inclusion (RFI) ‑ An attack that exploits vulnerable inclusion procedures in the\napplication, resulting in the inclusion of remote files.\n• Scalable Vector Graphics (SVG) –An XML‑based markup language for describing two‑\ndimensional based vector graphics.\n• Secure Real‑time Transport Protocol (SRTP) and Secure Real‑time Transport Control Proto‑\ncol (SRTCP) –A profile of the RTP and RTCP protocols providing support for message encryp‑\ntion, authentication and integrity protection. Defined in RFC 3711.\n• Security Architecture –An abstraction of an application’s design that identifies and describes\nwhere and how security controls are used, and also identifies and describes the location and\nsensitivity of both user and application data.\n• Security Assertion Markup Language (SAML) –An open standard for single sign‑on authenti‑\ncation based on passing signed assertions (usually XML objects) between the identity provider\nand the relying party.\n• Security Configuration –The runtime configuration of an application that affects how security\ncontrols are used.\n• Security Control –A function or component that performs a security check (e.g., an authoriza‑\ntion check) or when called results in a security effect (e.g., generating an audit record).\n• Security information and event management (SIEM) ‑ A system for threat detection, compli‑\nance and security incident management through the collection and analysis of security‑related\ndata from various sources within an organization’s IT infrastructure.\n• Self‑Contained Token –A token that encapsulates one or more attributes that do not rely on\nserver‑side state or other external storage. These tokens ensure the authenticity and integrity\nof their contained attributes, enabling secure, “stateless”information exchange across systems.\nSelf‑contained tokens are generally secured using cryptographic techniques, such as digital\nsignatures or message authentication codes (MACs), to ensure the authenticity, integrity, and\nin some cases the confidentiality of its data. Common examples include SAML Assertions and\nJWTs.\n• Server‑side Request Forgery (SSRF) –An attack that abuses functionality on the server to read\nor update internal resources. The attacker supplies or modifies a URL, which the code running\non the server will read or submit data to.\n• Session Description Protocol (SDP) –A message format for setting up multimedia session (used\nfor example in WebRTC). Defined in RFC 4566.\n• Session Identifier or Session ID –A key which identifies a stateful session stored at the back\nend. Will be transfered to and from the client either as or inside a “Reference Token”.\n• Session Token –A “catch‑all”phrase used in this standard to refer to the token or value used\nin either stateless session mechanisms (which use a self‑contained token) or stateful session\nmechanisms (which use a reference token).\n• Session Traversal Utilities for NAT (STUN) –A protocol used to assist NAT traversal in order to\nestablish peer‑to‑peer communications. Defined in RFC 3489.\n• Single‑factor authenticator –A mechanism to check that a user is authenticated. It should ei‑\n99",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 93
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nther be something you know (memorized secrets, passwords, passphrases, PINs), something\nyou are (biometrics, fingerprint, face scans), or something you have (OTP tokens, a crypto‑\ngraphic device such as a smart card).\n• Single Sign‑on Authentication (SSO) –This occurs when a user logs into one application and is\nthen automatically logged into other applications without having to re‑authenticate. For exam‑\nple, when logging into Google, the user will be automatically logged into other Google services\nsuch as YouTube, Google Docs, and Gmail.\n• Software bill of materials (SBOM) ‑ A structured, comprehensive list of all components, mod‑\nules, libraries, frameworks and other resources required to build or assemble a software appli‑\ncation.\n• Software Composition Analysis (SCA) –A set of technologies designed to analyze application\ncomposition, dependencies, libraries and packages for security vulnerabilities of specific com‑\nponent versions in use. This is not to be confused with source‑code analysis which is now com‑\nmonly referred to as SAST.\n• Software development lifecycle (SDLC) –The step‑by‑step process by which software is devel‑\noped going from the initial requirements to deployment and maintenance.\n• SQL Injection (SQLi) –A code injection technique used to attack data‑driven applications, in\nwhich malicious SQL statements are inserted into an entry point.\n• Stateful Session Mechanism –In a stateful session mechanism, the application retains session\nstate at the backend which typically corresponds to a session token, generated using a cryp‑\ntographically secure pseudo‑random number generator (CSPRNG), which is issued to the end\nuser.\n• Stateless Session Mechanism –A stateless session mechanism will use a self‑contained token\nwhich is passed to clients, and contains session information that is not necessarily stored within\nthe service which then receives and validates the token. In reality, a service will need to have\naccess to some session information (such as a JWT revocation list) in order to be able to enforce\nrequired security controls.\n• Static application security testing (SAST) –A set of technologies designed to analyze applica‑\ntion source code, byte code and binaries for coding and design conditions that are indicative of\nsecurity vulnerabilities. SAST solutions analyze an application from the “inside out”in a non‑\nrunning state.\n• Threat Modeling –A technique consisting of developing increasingly refined security architec‑\ntures to identify threat agents, security zones, security controls, and important technical and\nbusiness assets.\n• Time‑of‑check to time‑of‑use (TOCTOU) –A situation where an application checks the state\nof a resource before using that resource, but the resource’s state can be changed between the\ncheck and the use. This can invalidate the results of the check and cause a situation where the\napplication performs invalid actions due to this state mismatch.\n• Time based One‑time Passwords (TOTPs) ‑ A method of generating an OTP where the current\ntime acts as part of the algorithm to generate the password.\n• TLS client authentication, also called Mutual TLS (mTLS) –In a standard TLS connection, a\n100",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 94
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nclient can use the certificate provided by the server to validate the server’s identity. Where TLS\nclient authentication is used, the client also uses its own private key and certificate to allow the\nserver to also validate the client’s identity.\n• Transport Layer Security (TLS) –Cryptographic protocols that provide communication secu‑\nrity over a network connection.\n• Traversal Using Relays around NAT (TURN) –An extension of the STUN protocol using a TURN\nserver as a relay when direct peer‑to‑peer connections cannot be established. Defined in RFC\n8656.\n• Trusted execution environment (TEE) ‑ An isolated processing environment in which applica‑\ntions can be securely executed irrespective of the rest of the system.\n• Trusted Platform Module (TPM) –A type of HSM that is usually attached to a larger hardware\ncomponent such as a motherboard and acts as the “root of trust”for that system.\n• Trusted Service Layer –Any trusted control enforcement point, such as a microservice, server‑\nless API, server‑side, a trusted API on a client device that has secure boot, partner or external\nAPIs, and so on. Trusted means that there is no concern that an untrusted user will be able to\nbypass or skip the layer or controls implemented at that layer.\n• Uniform Resource Identifier (URI)‑ A unique string of characters that identifies a resource,\nsuch as webpage, mail address, places.\n• Uniform Resource Locator (URL) –A string that specifies the location of resource on the Inter‑\nnet.\n• Universally Unique Identifier (UUID) –A unique reference number used as an identifier in soft‑\nware.\n• Verifier –The person or team that is reviewing an application against the OWASP ASVS require‑\nments.\n• Web Real‑Time Communication (WebRTC) –A protocol stack and associated web API used for\nthe transport of multimedia streams in web applications, usually in the context of teleconfer‑\nencing. Based on SRTP, SRTCP, DTLS, SDP and STUN/TURN.\n• WebSocket over TLS (WSS) –A practice of securing WebSocket communication by layering\nWebSocket over TLS protocol.\n• What You See Is What You Get (WYSIWYG) –A type of rich content editor that shows how the\ncontent will actually look when rendered rather than showing the coding used to govern the\nrendering.\n• X.509 Certificate –An X.509 certificate is a digital certificate that uses the widely accepted in‑\nternational X.509 public key infrastructure (PKI) standard to verify that a public key belongs to\nthe user, computer or service identity contained within the certificate.\n• XML eXternal Entity (XXE) –A type of XML entity that can access local or remote content via a\ndeclared system identifier. This may lead to various injection attacks.\n101",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 95
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nAppendix B: References\nThe following OWASP projects are most likely to be useful to users/adopters of this standard:\nOWASP Core Projects\n1. OWASP Top 10 Project: https://owasp.org/www‑project‑top‑ten/\n2. OWASP Web Security Testing Guide: https://owasp.org/www‑project‑web‑security‑testing‑\nguide/\n3. OWASP Proactive Controls: https://owasp.org/www‑project‑proactive‑controls/\n4. OWASP Software Assurance Maturity Model (SAMM): https://owasp.org/www‑project‑samm/\n5. OWASP Secure Headers Project: https://owasp.org/www‑project‑secure‑headers/\nOWASP Cheat Sheet Series project\nThis project has several cheat sheets that will be relevant to different topics in the ASVS.\nThere is a mapping to the ASVS which can be found here: https://cheatsheetseries.owasp.org/Index\nASVS.html\nMobile Security Related Projects\n1. OWASP Mobile Security Project: https://owasp.org/www‑project‑mobile‑security/\n2. OWASP Mobile Top 10 Risks: https://owasp.org/www‑project‑mobile‑top‑10/\n3. OWASP Mobile Security Testing Guide and Mobile Application Security Verification Standard:\nhttps://owasp.org/www‑project‑mobile‑security‑testing‑guide/\nOWASP Internet of Things related projects\n1. OWASP Internet of Things Project: https://owasp.org/www‑project‑internet‑of‑things/\nOWASP Serverless projects\n1. OWASP Serverless Project: https://owasp.org/www‑project‑serverless‑top‑10/\nOthers\nSimilarly, the following websites are most likely to be useful to users/adopters of this standard\n1. SecLists Github: https://github.com/danielmiessler/SecLists\n2. MITRE Common Weakness Enumeration: https://cwe.mitre.org/\n102",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 96
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n3. PCI Security Standards Council: https://www.pcisecuritystandards.org/\n4. PCI Data Security Standard (DSS) v3.2.1 Requirements and Security Assessment Procedures:\nhttps://www.pcisecuritystandards.org/documents/PCI_DSS_v3‑2‑1.pdf\n5. PCI Software Security Framework ‑ Secure Software Requirements and Assessment Procedures:\nhttps://www.pcisecuritystandards.org/documents/PCI‑Secure‑Software‑Standard‑v1_0.pdf\n6. PCI Secure Software Lifecycle (Secure SLC) Requirements and Assessment Procedures: https:\n//www.pcisecuritystandards.org/documents/PCI‑Secure‑SLC‑Standard‑v1_0.pdf\n7. OWASP ASVS 4.0 Testing Guide https://github.com/BlazingWind/OWASP‑ASVS‑4.0‑testing‑\nguide\nAppendix C: Cryptography Standards\nThe “Cryptography”chapter goes beyond simply defining best practices. It aims to enhance under‑\nstanding of cryptography principles and encourage the adoption of more resilient, modern security\nmethods. This appendix provides detailed technical information regarding each requirement, com‑\nplementing the overarching standards outlined in the “Cryptography”chapter.\nThis appendix defines the level of approval for different cryptographic mechanisms:\n• Approved (A) mechanisms can be used in applications.\n• Legacy mechanisms (L) should not be used in applications but might still be used for compat‑\nibility with existing legacy applications or code onyly. While the usage of such these mech‑\nanisms is currently not considered to be a vulnerability in itself, they should be replaced by\nmore secure and future‑proof mechanisms as soon as possible.\n• Disallowed mechanisms (D) must not be used because they are currently considered broken or\ndo not provide sufficient security.\nThis list may be overridden in the context of a given application for various reasons including:\n• new evolutions in the field of cryptography;\n• compliance with regulation.\nCryptographic Inventory and Documentation\nThis section provides additional information for V11.1 Cryptographic Inventory and Documenta‑\ntion.\nIt is important to ensure that all cryptographic assets, such as algorithms, keys, and certificates, are\nregularly discovered, inventoried, and assessed. For Level 3, this should include the use of static and\ndynamic scanning to discover the use of cryptography in an application. Tools such as SAST and DAST\nmay help with this but it is possible that dedicated tools would be needed to get more comprehensive\ncoverage. Freeware examples of tools include:\n• CryptoMon ‑ Network Cryptography Monitor ‑ using eBPF, written in python\n103",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 97
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• Cryptobom Forge Tool: Generating Comprehensive CBOMs from CodeQL Outputs\nEquivalent Strengths of Cryptographic Parameters\nThe relative security strengths for various cryptographic systems are in this table (from NIST SP 800‑\n57 Part 1, p.71):\nSecurity Strength\nSymmetric Key\nAlgorithms\nFinite Field\nInteger\nFactorisation\nElliptic Curve\n<= 80\n2TDEA\nL = 1024 N = 160\nk = 1024\nf = 160‑223\n112\n3TDEA\nL = 2048 N = 224\nk = 2048\nf = 224‑255\n128\nAES‑128\nL = 3072 N = 256\nk = 3072\nf = 256‑383\n192\nAES‑192\nL = 7680 N = 384\nk = 7680\nf = 384‑511\n256\nAES‑256\nL = 15360 N = 512\nk = 15360\nf = 512+\nExample of applications:\n• Finite Field Cryptography: DSA, FFDH, MQV\n• Integer Factorisation Cryptography: RSA\n• Elliptic Curve Cryptography: ECDSA, EdDSA, ECDH, MQV\nNote: that this section assumes that no quantum computer exists; if such a computer would exist,\nthe estimates for the last 3 columns would be no longer valid.\nRandom Values\nThis section provides additional information for V11.5 Random Values.\nName\nVersion/Reference\nNotes\nStatus\n/dev/random\nLinux 4.8+ (Oct 2016),\nalso found in iOS,\nAndroid, and other\nLinux‑based POSIX\noperating systems.\nBased on RFC7539\nUtilizing ChaCha20\nstream. Found in iOS\nSecRandomCopyBytes\nand Android Secure\nRandom with the\ncorrect settings\nprovided to each.\nA\n104",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 98
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nName\nVersion/Reference\nNotes\nStatus\n/dev/urandom\nLinux kernel’s special\nfile for providing\nrandom data\nProvides high‑quality,\nentropy sources from\nhardware randomness\nA\nAES-CTR-DRBG\nNIST SP800‑90A\nAs used in common\nimplementations,\nsuch as Windows CNG\nAPI BCryptGenRandom\nset by\nBCRYPT_RNG_ALGORITHM.\nA\nHMAC-DRBG\nNIST SP800‑90A\nA\nHash-DRBG\nNIST SP800‑90A\nA\ngetentropy()\nOpenBSD, available in\nLinux glibc 2.25+ and\nmacOS 10.12+\nProvides secure\nrandom bytes directly\nfrom the kernel’s\nentropy source with a\nstraightforward and\nminimal API. It’s more\nmodern and avoids\npitfalls associated with\nolder APIs.\nA\nThe underlying hash function used with HMAC‑DRBG or Hash‑DRBG must be approved for this us‑\nage.\nCipher Algorithms\nThis section provides additional information for V11.3 Encryption Algorithms.\nApproved cipher algorithms are listed in order of preference.\nSymmetric Key Algorithms\nReference\nStatus\nAES‑256\nFIPS 197\nA\nSalsa20\nSalsa 20 specification\nA\nXChaCha20\nXChaCha20 Draft\nA\nXSalsa20\nExtending the Salsa20 nonce\nA\n105",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 99
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nSymmetric Key Algorithms\nReference\nStatus\nChaCha20\nRFC 8439\nA\nAES‑192\nFIPS 197\nA\nAES‑128\nFIPS 197\nL\n2TDEA\nD\nTDEA (3DES/3DEA)\nD\nIDEA\nD\nRC4\nD\nBlowfish\nD\nARC4\nD\nDES\nD\nAES Cipher Modes\nBlock ciphers, such as AES, can be used with different modes of operations. Many modes of oper‑\nations, such as Electronic codebook (ECB), are insecure and must not be used. The Galois/Counter\nMode (GCM) and Counter with cipher block chaining message authentication code (CCM) modes of\noperations provide authenticated encryption and should be used in modern applications.\nApproved modes are listed in order of preference.\nMode\nAuthenticated\nReference\nStatus\nRestriction\nGCM\nYes\nNIST SP 800‑38D\nA\nCCM\nYes\nNIST SP 800‑38C\nA\nCBC\nNo\nNIST SP 800‑38A\nL\nCCM‑8\nYes\nD\nECB\nNo\nD\nCFB\nNo\nD\nOFB\nNo\nD\nCTR\nNo\nD\nNotes:\n• All encrypted messages must be authenticated. For ANY use of CBC mode there MUST be an\nassociated hashing MAC algorithm to validate the message. In general, this MUST be applied in\n106",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 100
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nthe Encrypt‑Then‑Hash method (but TLS 1.2 uses Hash‑Then‑Encrypt instead). If this cannot\nbe guaranteed, then CBC MUST NOT be used. The only application where encryption without\na MAC algorithm is allowed is disk encryption.\n• If CBC is used, it shall be guaranteed that the verification of the padding is performed in con‑\nstant time.\n• When using CCM‑8, the MAC tag only has 64 bits of security. This does not conform to require‑\nment 6.2.9 which requires at least 128 bits of security.\n• Disk encryption is considered out of scope for the ASVS. Therefore this appendix does not list\nany approved method for disk encryption. For this usage, encryption without authentication is\nusually accepted and the XTS, XEX and LRW modes are typically used.\nKey Wrapping\nCryptographic key wrap (and corresponding key unwrap) is a method of protecting an existing key\nby encapsulating (i.e., wrapping) it by employing an additional encryption mechanism so that the\noriginal key is not obviously exposed, e.g., during a transfer. This additional key used to protect the\noriginal key is referred to as the wrap key.\nThis operation may be performed when it is desirable to protect keys in places deemed untrustwor‑\nthy, or to send sensitive keys over untrusted networks or within applications. However, serious con‑\nsideration should be given to understanding the nature (e.g., the identity and the purpose) of the\noriginal key prior to committing to a wrap/unwrap procedure as this may have repercussions for\nboth source and target systems/applications in terms of security and especially compliance which\nmay include audit trails of a key’s function (e.g., signing) as well as appropriate key storage.\nSpecifically, AES‑256 MUST be used for key wrapping, following NIST SP 800‑38F and considering\nforward‑looking provisions against the quantum threat. Cipher modes using AES are the following,\nin order of preference:\nKey Wrapping\nReference\nStatus\nKW\nNIST SP 800‑38F\nA\nKWP\nNIST SP 800‑38F\nA\nAES‑192 and AES‑128 MAY be used if the use case demands it, but its motivation MUST be documented\nin the entity’s cryptography inventory.\nAuthenticated Encryption\nWith the exception of disk encryption, encrypted data must be protected against unauthorized mod‑\nification using some form of authenticated encryption (AE) scheme, usually using an authenticated\nencryption with associated data (AEAD) scheme.\n107",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 101
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nThe application should preferably use an approved AEAD scheme. It might alternatively combine an\napproved cipher scheme and an approved MAC algorithm with a Encrypt‑then‑MAC construct.\nMAC‑then‑encrypt is still allowed for compatibility with legacy applications. It is used in TLS v1.2\nwith old ciphers suites.\nAEAD mechanism\nReference\nStatus\nAES‑GCM\nSP 800‑38D\nA\nAES‑CCM\nSP 800‑38C\nA\nChaCha‑Poly1305\nRFC 7539\nA\nAEGIS‑256\nAEGIS: A Fast\nAuthenticated\nEncryption\nAlgorithm (v1.1)\nA\nAEGIS‑128\nAEGIS: A Fast\nAuthenticated\nEncryption\nAlgorithm (v1.1)\nA\nAEGIS‑128L\nAEGIS: A Fast\nAuthenticated\nEncryption\nAlgorithm (v1.1)\nA\nEncrypt‑then‑MAC\nA\nMAC‑then‑encrypt\nL\nHash Functions\nThis section provides additional information for V11.4 Hashing and Hash‑based Functions.\nHash Functions for General Use Cases\nThe following table lists hash functions approved in general cryptographic use cases such as digital\nsignatures:\n• Approved hash functions provide strong collision resistance and are suitable for high‑security\napplications.\n• Some of these algorithms offer strong resistance to attacks when used with proper crypto‑\ngraphic key management, and so are additionally approved for HMAC, KDF, and RBG func‑\ntions.\n108",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 102
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\n• Hash function with less than 254 bit of output have insufficient collision resistancea and must\nnot be used for digital signature or other applications requiring collision resistance. For other\nusages, they might be used for compatibility and verification ONLY with legacy systems but\nmust not be used in new designs.\nHash function\nReference\nStatusRestrictions\nSHA3‑512\nFIPS 202\nA\nSHA‑512\nFIPS 180‑4\nA\nSHA3‑384\nFIPS 202\nA\nSHA‑384\nFIPS 180‑4\nA\nSHA3‑256\nFIPS 202\nA\nSHA‑512/256\nFIPS 180‑4\nA\nSHA‑256\nFIPS 180‑4\nA\nSHAKE256\nFIPS 202\nA\nBLAKE2s\nBLAKE2: simpler, smaller, fast as MD5\nA\nBLAKE2b\nBLAKE2: simpler, smaller, fast as MD5\nA\nBLAKE3\nBLAKE3 one function, fast everywhere\nA\nSHA‑224\nFIPS 180‑4\nL\nNot\nsuit‑\nable\nfor\nHMAC,\nKDF,\nRBG,\ndig‑\ni‑\ntal\nsig‑\nna‑\ntures\n109",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 103
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nHash function\nReference\nStatusRestrictions\nSHA‑512/224\nFIPS 180‑4\nL\nNot\nsuit‑\nable\nfor\nHMAC,\nKDF,\nRBG,\ndig‑\ni‑\ntal\nsig‑\nna‑\ntures\nSHA3‑224\nFIPS 202\nL\nNot\nsuit‑\nable\nfor\nHMAC,\nKDF,\nRBG,\ndig‑\ni‑\ntal\nsig‑\nna‑\ntures\n110",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 104
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nHash function\nReference\nStatusRestrictions\nSHA‑1\nRFC 3174 & RFC 6194\nL\nNot\nsuit‑\nable\nfor\nHMAC,\nKDF,\nRBG,\ndig‑\ni‑\ntal\nsig‑\nna‑\ntures\nCRC (any\nlength)\nD\nMD4\nRFC 1320\nD\nMD5\nRFC 1321\nD\nHash Functions for Password Storage\nFor secure password hashing, dedicated hash functions must be used. These slow‑hashing algo‑\nrithms mitigate brute‑force and dictionary attacks by increasing the computational difficulty of pass‑\nword cracking.\nKDF\nReference\nRequired Parameters\nStatus\nargon2id RFC 9106\nt = 1: m ≥47104 (46 MiB), p = 1t = 2: m ≥19456\n(19 MiB), p = 1t ≥3: m ≥12288 (12 MiB), p = 1\nA\nscrypt\nRFC 7914\np = 1: N ≥2^17 (128 MiB), r = 8p = 2: N ≥2^16\n(64 MiB), r = 8p ≥3: N ≥2^15 (32 MiB), r = 8\nA\nbcrypt\nA Future‑Adaptable\nPassword Scheme\ncost ≥10\nA\nPBKDF2‑\nHMAC‑\nSHA‑\n512\nNIST SP 800‑132, FIPS\n180‑4\niterations ≥210,000\nA\n111",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 105
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nKDF\nReference\nRequired Parameters\nStatus\nPBKDF2‑\nHMAC‑\nSHA‑\n256\nNIST SP 800‑132, FIPS\n180‑4\niterations ≥600,000\nA\nPBKDF2‑\nHMAC‑\nSHA‑1\nNIST SP 800‑132, FIPS\n180‑4\niterations ≥1,300,000\nL\nApproved password‑based key derivations functions can be used for password storage.\nKey Derivation Functions (KDFs)\nGeneral Key Derivation Functions\nKDF\nReference\nStatus\nHKDF\nRFC 5869\nA\nTLS 1.2 PRF\nRFC 5248\nL\nMD5‑based\nKDFs\nRFC 1321\nD\nSHA‑1‑based\nKDFs\nRFC 3174 & RFC 6194\nD\nPassword‑based Key Derivation Functions\nKDF\nReference\nRequired Parameters\nStatus\nargon2id RFC 9106\nt = 1: m ≥47104 (46 MiB), p = 1t = 2: m ≥19456\n(19 MiB), p = 1t ≥3: m ≥12288 (12 MiB), p = 1\nA\nscrypt\nRFC 7914\np = 1: N ≥2^17 (128 MiB), r = 8p = 2: N ≥2^16\n(64 MiB), r = 8p ≥3: N ≥2^15 (32 MiB), r = 8\nA\nPBKDF2‑\nHMAC‑\nSHA‑\n512\nNIST SP 800‑132, FIPS\n180‑4\niterations ≥210,000\nA\n112",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 106
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nKDF\nReference\nRequired Parameters\nStatus\nPBKDF2‑\nHMAC‑\nSHA‑\n256\nNIST SP 800‑132, FIPS\n180‑4\niterations ≥600,000\nA\nPBKDF2‑\nHMAC‑\nSHA‑1\nNIST SP 800‑132, FIPS\n180‑4\niterations ≥1,300,000\nL\nKey Exchange Mechanisms\nThis section provides additional information for V11.6 Public Key Cryptography.\nKEX Schemes\nA security strength of 112 bits or above MUST be ensured for all Key Exchange schemes, and their\nimplementation MUST follow the parameter choices in the following table.\nScheme\nDomain Parameters\nForward Secrecy\nStatus\nFinite Field Diffie‑Hellman (FFDH)\nL >= 3072 & N >= 256\nYes\nA\nElliptic Curve Diffie‑Hellman (ECDH)\nf >= 256‑383\nYes\nA\nEncrypted key transport with RSA‑PKCS#1 v1.5\nNo\nD\nWhere the following parameters are:\n• k is the key size for RSA keys.\n• L is the size of the public key and N is the size of the private key for finite field cryptography.\n• f is the range of key sizes for ECC.\nAny new implementation MUST NOT use any scheme that is NOT compliant with NIST SP 800‑56A &\nB and NIST SP 800‑77. Specifically, IKEv1 MUST NOT be used in production.\nDiffie‑Hellman groups\nThe following groups are approved for implementations of Diffie‑Hellman key exchange. Security\nstrengths are documented in NIST SP 800‑56A, Appendix D, and NIST SP 800‑57 Part 1 Rev.5.\n113",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 107
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nGroup\nStatus\nP‑224, secp224r1\nA\nP‑256, secp256r1\nA\nP‑384, secp384r1\nA\nP‑521, secp521r1\nA\nK‑233, sect233k1\nA\nK‑283, sect283k1\nA\nK‑409, sect409k1\nA\nK‑571, sect571k1\nA\nB‑233, sect233r1\nA\nB‑283, sect283r1\nA\nB‑409, sect409r1\nA\nB‑571, sect571r1\nA\nCurve448\nA\nCurve25519\nA\nMODP‑2048\nA\nMODP‑3072\nA\nMODP‑4096\nA\nMODP‑6144\nA\nMODP‑8192\nA\nffdhe2048\nA\nffdhe3072\nA\nffdhe4096\nA\nffdhe6144\nA\nffdhe8192\nA\nMessage Authentication Codes (MAC)\nMessage Authentication Codes (MACs) are cryptographic constructs used to verify the integrity and\nauthenticity of a message. A MAC takes a message and a secret key as inputs and produces a fixed‑\nsize tag (the MAC value). MACs are widely used in secure communication protocols (e.g., TLS/SSL) to\nensure that messages exchanged between parties are authentic and intact.\n114",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 108
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nMAC\nAlgorithm\nReference\nStatus Restrictions\nHMAC‑\nSHA‑256\nRFC 2104 & FIPS 198‑1\nA\nHMAC‑\nSHA‑384\nRFC 2104 & FIPS 198‑1\nA\nHMAC‑\nSHA‑512\nRFC 2104 & FIPS 198‑1\nA\nKMAC128\nNIST SP 800‑185\nA\nKMAC256\nNIST SP 800‑185\nA\nBLAKE3\n(keyed_hash\nmode)\nBLAKE3 one function, fast everywhere\nA\nAES‑\nCMAC\nRFC 4493 & NIST SP 800‑38B\nA\nAES‑\nGMAC\nNIST SP 800‑38D\nA\nPoly1305‑\nAES\nThe Poly1305‑AES message‑authentication code\nA\nHMAC‑\nSHA‑1\nRFC 2104 & FIPS 198‑1\nL\nHMAC‑\nMD5\nRFC 1321\nD\nDigital Signatures\nSignature schemes MUST use approved key sizes and parameters per NIST SP 800‑57 Part 1.\nSignature Algorithm\nReference\nStatus\nEdDSA (Ed25519, Ed448)\nRFC 8032\nA\nXEdDSA (Curve25519,\nCurve448)\nXEdDSA\nA\nECDSA (P‑256, P‑384, P‑521)\nFIPS 186‑4\nA\nRSA‑RSSA‑PSS\nRFC 8017\nA\n115",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 109
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nSignature Algorithm\nReference\nStatus\nRSA‑SSA‑PKCS#1 v1.5\nRFC 8017\nD\nDSA (any key size)\nFIPS 186‑4\nD\nPost‑Quantum Encryption Standards\nPQC implementations must be in line with FIPS‑203/204/205 as there is minimal hardened code nor\nimplementation reference yet. https://www.nist.gov/news‑events/news/2024/08/nist‑releases‑first‑3‑\nfinalized‑post‑quantum‑encryption‑standards\nThe proposed mlkem768x25519 post‑quantum hybrid TLS key agreement method is supported by\nmajor browsers such as Firefox release 132 and Chrome release 131. It may be used in cryptographic\ntesting environments or when available within industry‑ or government‑approved libraries.\nAppendix D: Recommendations\nIntroduction\nWhilst preparing version 5.0 of the Application Security Verification Standard (ASVS), it became clear\nthat there were a number of existing and newly suggested items that shouldn’t be included as require‑\nments in 5.0. This may have been because they were not in scope for ASVS as per the definition for\n5.0 or alternatively it was felt that while they were a good idea, they could not be made mandatory.\nNot wanting to lose all these items entirely, some have been captured in this appendix.\nRecommended, in‑scope mechanisms\nThe following items are in‑scope for ASVS. They should not be made mandatory but it is strongly\nrecommended to consider them as part of a secure application.\n• A password strength meter should provided to help users set a stronger password.\n• Create a publicly available security.txt file at the root or .well‑known directory of the application\nthat clearly defines a link or e‑mail address for people to contact owners about security issues.\n• Client‑side input validation should be enforced in addition to validation at a trusted service\nlayer as this provides a good opportunity to discover when someone has bypassed client‑side\ncontrols in an attempt to attack the application.\n• Prevent accidentally accessible and sensitive pages from appearing in search engines using a\nrobots.txt file, the X‑Robots‑Tag response header or a robots html meta tag.\n• When using GraphQL, implement authorization logic at the business logic layer instead of the\nGraphQL or resolver layer to avoid having to handle authorization on every separate interface.\n116",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 110
        }
    },
    {
        "page_content": "Application Security Verification Standard\nMay 2025\nReferences:\n• More information on security.txt including a link to the RFC\nSoftware Security principles\nThe following items were previously in ASVS but are not really requirements. Rather they are prin‑\nciples to consider when implementing security controls that when followed will lead to more robust\ncontrols. These include:\n• Security controls should be centralized, simple (economy of design), verifiably secure, and\nreusable. This should avoid duplicate, missing, or ineffective controls.\n• Wherever possible, use previously written and well‑vetted security control implementations\nrather than relying on implementing controls from scratch.\n• Ideally, a single access control mechanism should be used to access protected data and re‑\nsources. All requests should pass through this single mechanism to avoid copy and paste or\ninsecure alternative paths.\n• Attribute or feature‑based access control is a recommended pattern whereby the code checks\nthe user’s authorization for a feature or data item rather than just their role. Permissions should\nstill be allocated using roles.\nSoftware Security processes\nThere are a number of security processes which were removed from ASVS 5.0 but are still a good idea.\nThe OWASP SAMM project may be a good source for how to effectively implement these processes.\nThe items which were previously in ASVS include:\n• Verify the use of a secure software development lifecycle that addresses security in all stages\nof development.\n• Verify the use of threat modeling for every design change or sprint planning to identify threats,\nplan for countermeasures, facilitate appropriate risk responses, and guide security testing.\n• Verify that all user stories and features contain functional security constraints, such as “As a\nuser, I should be able to view and edit my profile. I should not be able to view or edit anyone\nelse’s profile”\n• Verify availability of a secure coding checklist, security requirements, guideline, or policy to\nall developers and testers.\n• Verify that an ongoing process exists to ensure that the application source code is free from\nbackdoors, malicious code (e.g., salami attacks, logic bombs, time bombs), and undocumented\nor hidden features (e.g., Easter eggs, insecure debugging tools). Complying with this section\nis not possible without complete access to source code, including third‑party libraries, and is\ntherefore probably only suitable for applications requiring the very highest levels of security.\n117",
        "metadata": {
            "source": "OWASP_Application_Security_Verification_Standard_5.0.0.pdf",
            "page": 111
        }
    }
]